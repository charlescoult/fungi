{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "518a0c58",
   "metadata": {},
   "source": [
    "# Model Generation for GBIF Fungi Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbc8a5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_ver = \"0.0.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b411778a",
   "metadata": {},
   "source": [
    "## References\n",
    "* [Transfer Learning with Hub](https://www.tensorflow.org/tutorials/images/transfer_learning_with_hub)\n",
    "* [`tf.data`: Build TensorFlow input pipelines](https://www.tensorflow.org/guide/data?hl=en)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbff1eb9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a285c8a1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2c0f4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "from keras.utils.layer_utils import count_params\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "import logging\n",
    "\n",
    "# Set logging to output INFO level to standard output\n",
    "logging.basicConfig(level=os.environ.get(\"LOGLEVEL\", \"INFO\"))\n",
    "\n",
    "# Set tf logging level to WARN\n",
    "tf.get_logger().setLevel( 'WARN' )\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a639289",
   "metadata": {},
   "source": [
    "### Limit GPU memory allocation\n",
    "[Limiting GPU Memory Growth](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16845159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_memory_growth(limit=True):\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            # Currently, memory growth needs to be the same across GPUs\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, limit)\n",
    "            logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "        except RuntimeError as e:\n",
    "            # Memory growth must be set before GPUs have been initialized\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10a47939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "limit_memory_growth()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdb62bf",
   "metadata": {},
   "source": [
    "### Multi-GPU strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d222460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strategy = tf.distribute.MirroredStrategy( devices = [ \"/gpu:0\", \"/gpu:1\" ] )\n",
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106e1972",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c19476",
   "metadata": {},
   "source": [
    "## `runs` DataFrame\n",
    "Keeps track of all runs performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60bdfc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_dir = '/media/data/runs'\n",
    "runs_hdf = 'runs.h5'\n",
    "runs_hdf_key = 'runs'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2704ae3",
   "metadata": {},
   "source": [
    "## `run` Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b511946",
   "metadata": {},
   "source": [
    "The `run` dictionary will keep track of this run's user-defined hyperparameters as well as generated parameters such as random seeds and file paths. This information will be saved in the `runs_hdf` specified above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d702f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = {}\n",
    "# use a formatted timestamp as the run's ID\n",
    "run['id'] = datetime.datetime.now().strftime('%Y_%m_%d-%H_%M_%S')\n",
    "run['notebook_ver'] = notebook_ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7603b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/data/runs/2023_03_19-15_07_43'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the path of the directory where this run's files will be stored (metadata, saved model(s), etc.)\n",
    "run['path'] = os.path.join( runs_dir, str(run['id']) )\n",
    "run['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce638f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will overwrite existing run in dataframe with the same id\n",
    "# - allows updating as we go\n",
    "def save_run_metadata(\n",
    "    run,\n",
    "    index = 'id',\n",
    "):\n",
    "    # create df from run using json_normalize to flatten dict\n",
    "    run_df = pd.json_normalize( run )\n",
    "    run_df = run_df.set_index( index )\n",
    "\n",
    "    # create runs_df if it doesn't exist\n",
    "    runs_hdf_path = os.path.join( runs_dir, runs_hdf )\n",
    "    if ( not os.path.isfile( runs_hdf_path ) ):\n",
    "        pd.DataFrame().to_hdf( runs_hdf_path, runs_hdf_key )\n",
    "    \n",
    "    # read in the runs_hdf\n",
    "    runs_df = pd.read_hdf(\n",
    "        runs_hdf_path,\n",
    "        runs_hdf_key,\n",
    "    )\n",
    "    \n",
    "    # If a row for this run already exists, remove it\n",
    "    if ( run[ index ] in runs_df.index ):\n",
    "        runs_df = runs_df.drop( run[ index ] )\n",
    " \n",
    "    # Add the updated data\n",
    "    runs_df = pd.concat(\n",
    "        [ runs_df, run_df ],\n",
    "    )\n",
    "    \n",
    "    # save to file\n",
    "    runs_df.to_hdf( runs_hdf_path, runs_hdf_key )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cec731ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_run_metadata( run ):\n",
    "    print( json.dumps( run, indent = 3 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37f84a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the run path doesn't already exist and create it\n",
    "if (os.path.exists( run['path'] )):\n",
    "    logging.warn(\"Run path already exists!!\")\n",
    "    logging.warn(\" Overwriting: %s\" % run['path'])\n",
    "else:\n",
    "    os.makedirs( run['path'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d1027ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"id\": \"2023_03_19-15_07_43\",\n",
      "   \"notebook_ver\": \"0.0.1\",\n",
      "   \"path\": \"/media/data/runs/2023_03_19-15_07_43\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print_run_metadata( run )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae653da",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3105e4c2",
   "metadata": {},
   "source": [
    "## Enumerate Available Base Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c66022f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        source,\n",
    "        input_dim,\n",
    "        preprocessor,\n",
    "    ):\n",
    "        self.source = source\n",
    "        self.input_dim = input_dim\n",
    "        self.preprocessor = preprocessor\n",
    "    \n",
    "base_models = {\n",
    "    'MobileNet_v2': BaseModel(\n",
    "        source = 'https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4',\n",
    "        input_dim = 224,\n",
    "        # https://www.tensorflow.org/hub/common_signatures/images#input\n",
    "        # The inputs pixel values are scaled between -1 and 1, sample-wise.\n",
    "        preprocessor = tf.keras.applications.mobilenet_v2.preprocess_input,\n",
    "    ),\n",
    "\n",
    "    'Inception_v3': BaseModel(\n",
    "        source = 'https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/4',\n",
    "        input_dim = 299,\n",
    "        # The inputs pixel values are scaled between -1 and 1, sample-wise.\n",
    "        preprocessor = tf.keras.applications.inception_v3.preprocess_input,\n",
    "    ),\n",
    "\n",
    "    'Inception_v3_iNaturalist': BaseModel(\n",
    "        source = 'https://tfhub.dev/google/inaturalist/inception_v3/feature_vector/5',\n",
    "        input_dim = 299,\n",
    "        # The inputs pixel values are scaled between -1 and 1, sample-wise.\n",
    "        preprocessor = tf.keras.applications.inception_v3.preprocess_input,\n",
    "    ),\n",
    "\n",
    "    'Xception': BaseModel(\n",
    "        source = tf.keras.applications.Xception,\n",
    "        input_dim = 299,\n",
    "        # The inputs pixel values are scaled between -1 and 1, sample-wise.\n",
    "        preprocessor = tf.keras.applications.xception.preprocess_input,\n",
    "    ),\n",
    "\n",
    "    'ResNet101': BaseModel(\n",
    "        source = tf.keras.applications.resnet.ResNet101,\n",
    "        input_dim = 224,\n",
    "        preprocessor = tf.keras.applications.resnet50.preprocess_input,\n",
    "    ),\n",
    "\n",
    "    'ResNet50': BaseModel(\n",
    "        source = tf.keras.applications.ResNet50,\n",
    "        input_dim = 224,\n",
    "        preprocessor = tf.keras.applications.resnet50.preprocess_input,\n",
    "    ),\n",
    "\n",
    "    'Inception_ResNet_v2': BaseModel(\n",
    "        source = tf.keras.applications.InceptionResNetV2,\n",
    "        input_dim = 299,\n",
    "        preprocessor = tf.keras.applications.inception_resnet_v2.preprocess_input,\n",
    "    ),\n",
    "\n",
    "    'EfficientNet_v2': BaseModel(\n",
    "        source = tf.keras.applications.efficientnet_v2.EfficientNetV2B0,\n",
    "        input_dim = 224,\n",
    "        # The preprocessing logic has been included in the EfficientNetV2\n",
    "        # model implementation. Users are no longer required to call this\n",
    "        # method to normalize the input data. This method does nothing and\n",
    "        # only kept as a placeholder to align the API surface between old\n",
    "        # and new version of model.\n",
    "        preprocessor = tf.keras.applications.efficientnet_v2.preprocess_input,\n",
    "    ),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf8d406",
   "metadata": {},
   "source": [
    "## Enumerate Available Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15af0de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetHDFSource:\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        path,\n",
    "        key,\n",
    "        col_filename = 'filename',\n",
    "        col_label = 'label',\n",
    "    ):\n",
    "        self.path = path\n",
    "        self.key = key\n",
    "        self.col_filename = col_filename\n",
    "        self.col_label = col_label\n",
    "\n",
    "datasets = {\n",
    "    'gbif': DatasetHDFSource(\n",
    "        '/media/data/gbif/clean_data.h5',\n",
    "        'media_merged_filtered-by-species_350pt',\n",
    "        col_label = 'acceptedScientificName',\n",
    "    ),\n",
    "    'cub': DatasetHDFSource(\n",
    "        '/media/data/cub/cub.h5',\n",
    "        'cub',\n",
    "        col_filename = 'file_path',\n",
    "        col_label = 'class_name',\n",
    "    ),\n",
    "}\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53c36c8",
   "metadata": {},
   "source": [
    "### Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04d850ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.update( {\n",
    "    # \"id\": \"2023_03_19-14_13_29\",\n",
    "    # \"notebook_ver\": \"0.0.1\",\n",
    "    # \"path\": \"/media/data/runs/2023_03_19-14_13_29\",\n",
    "    \"batch_size\": 64,\n",
    "    \"max_epochs\": 50,\n",
    "    \"label_smoothing\": 0.1,\n",
    "    \"model\": {\n",
    "        \"learning_rate\": 0.0001, # Adam Optimizer\n",
    "        \"classifier\": {\n",
    "            \"dropout\": 0.33,\n",
    "            \"output_logits\": True\n",
    "        },\n",
    "        \"base\": \"Inception_v3_iNaturalist\"\n",
    "    },\n",
    "    \"dataset\": {\n",
    "        \"downsample\": \"min\",\n",
    "        \"source\": \"cub\",\n",
    "        \"split_test\": 0.05,\n",
    "        \"split_val\": 0.1,\n",
    "        # \"seed_split_test\": 2907756077,\n",
    "        # \"seed_split_val\": 973073386,\n",
    "        # \"seed_shuffle\": 7296619955565341716\n",
    "    }, # run['callbacks']['early_stopping']['restore_best_weights'],\n",
    "    \"callbacks\": {\n",
    "        \"early_stopping\": {\n",
    "            \"restore_best_weights\": True,\n",
    "        }\n",
    "    }\n",
    "    # \"label_mapping_path\": \"/media/data/runs/2023_03_19-14_13_29/label_mapping.json\"\n",
    "} )\n",
    "\n",
    "# TODO: allow loading of model weights from previous run\n",
    "load_weights = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3804c4e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_56896/3436063570.py:32: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->Index(['notebook_ver', 'path', 'label_mapping_path',\n",
      "       'model.classifier.output_logits', 'model.base', 'dataset.downsample',\n",
      "       'dataset.source', 'callbacks.early_stopping.restore_best_weights'],\n",
      "      dtype='object')]\n",
      "\n",
      "  runs_df.to_hdf( runs_hdf_path, runs_hdf_key )\n"
     ]
    }
   ],
   "source": [
    "save_run_metadata( run )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6595e67a",
   "metadata": {},
   "source": [
    "### Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e9b5d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "timer = {}\n",
    "timer['start'] = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b5b5ac",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12133130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in source dataframe\n",
    "ds_df = pd.read_hdf(\n",
    "    datasets[ run['dataset']['source'] ].path,\n",
    "    datasets[ run['dataset']['source'] ].key,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb506886",
   "metadata": {},
   "source": [
    "### Dataset Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4608af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label count: 200\n",
      "Datapoint count: 11788\n"
     ]
    }
   ],
   "source": [
    "ds_classes = ds_df[ datasets[ run['dataset']['source'] ].col_label ].unique().tolist()\n",
    "print('Label count: %d' % len(ds_classes))\n",
    "print('Datapoint count: %d' % len(ds_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c17dbad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_label_mapping(\n",
    "    label_mapping,\n",
    "    file_path = './label_mapping.json',\n",
    "):\n",
    "    with open( file_path, 'w' ) as f:\n",
    "        json.dump( label_mapping, f, indent = 3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92876643",
   "metadata": {},
   "outputs": [],
   "source": [
    "run['label_mapping_path'] = os.path.join( run['path'], 'label_mapping.json' )\n",
    "save_label_mapping(\n",
    "    ds_classes,\n",
    "    file_path = run['label_mapping_path'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "828f1236",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_df_label_vc = ds_df[ datasets[ run['dataset']['source'] ].col_label ].value_counts()\n",
    "ds_df_label_vc = ds_df_label_vc.sort_values( ascending = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a9e3c4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Black footed Albatross    60\n",
       "Red eyed Vireo            60\n",
       "Rose breasted Grosbeak    60\n",
       "Pine Grosbeak             60\n",
       "Evening Grosbeak          60\n",
       "Name: class_name, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_df_label_vc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1cdc99d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Whip poor Will       49\n",
       "Rhinoceros Auklet    48\n",
       "Spotted Catbird      45\n",
       "Crested Auklet       44\n",
       "Least Auklet         41\n",
       "Name: class_name, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_df_label_vc.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bfb4981b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_df_label_vc.hist( bins = 50 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abf9357",
   "metadata": {},
   "source": [
    "Most classes have 350 datapoints because I *thought* I had downsampled the datasets with more than 350 datapoints down to 350 but it looks like there are some that were not affected by the transformation I performed. There are some classes with more than 350 datapoints somehow. Regardless, we will be downsampling them all to the lowest value_count (101)..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e853b53e",
   "metadata": {},
   "source": [
    "### Dataset Transformation\n",
    "(downsample, upsample, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8de0672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampling to least number of samples per class: 41\n"
     ]
    }
   ],
   "source": [
    "# Downsample to equal number of samples per class if downsample param is set\n",
    "if ( run['dataset']['downsample'] ):\n",
    "    # if downsample param is 'min', downsample all classes to the same number of\n",
    "    # samples as the class with the least samples\n",
    "    if ( run['dataset']['downsample'] == 'min' ):\n",
    "        ds_df_label_vc_min = ds_df_label_vc.min()\n",
    "        print('Downsampling to least number of samples per class: %d' % ds_df_label_vc_min)\n",
    "    else:\n",
    "        # manual override\n",
    "        if ( run['dataset']['downsample'] > 0 ):\n",
    "            print( 'Overriding samples per class to: %d' % run['dataset']['downsample'] )\n",
    "            ds_df_label_vc_min = run['dataset']['downsample']\n",
    "        else: raise Exception(\"dataset downsample invalid\")\n",
    "    \n",
    "    # downsample based on \n",
    "    ds_df_trans = ds_df.groupby( by = datasets[ run['dataset']['source'] ].col_label ).sample( n = ds_df_label_vc_min )\n",
    "    ds_df_trans[ datasets[ run['dataset']['source'] ].col_label ].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3bb10a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41    200\n",
       "Name: class_name, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verifying that our downsampling worked - all classes should have the same value_count\n",
    "ds_df_trans[ datasets[ run['dataset']['source'] ].col_label ].value_counts().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a66265",
   "metadata": {},
   "source": [
    "We have transformed the original dataset through downsampling to produce a dataset where all classes have the same number of datapoints as the class with the least amount of datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27c1d12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New datapoint count: 8200\n"
     ]
    }
   ],
   "source": [
    "print( 'New datapoint count: %d' % len(ds_df_trans) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d63aa1b",
   "metadata": {},
   "source": [
    "### Train, Validation, Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6507235",
   "metadata": {},
   "outputs": [],
   "source": [
    "run['dataset']['split_test'] = 0.05\n",
    "run['dataset']['split_val'] = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5d088d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate random states for reproducability\n",
    "import random\n",
    "\n",
    "# [0, 2**32 - 1]\n",
    "run['dataset']['seed_split_test'] = random.randint( 0, 2**32 - 1 )\n",
    "run['dataset']['seed_split_val'] = random.randint( 0, 2**32 - 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "722fd1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "ds_df_train, ds_df_test = train_test_split(\n",
    "    ds_df_trans,\n",
    "    test_size = run['dataset']['split_test'],\n",
    "    stratify = ds_df_trans[[ datasets[ run['dataset']['source'] ].col_label ]],\n",
    "    random_state = run['dataset']['seed_split_test'],\n",
    ")\n",
    "\n",
    "# val\n",
    "ds_df_train, ds_df_val = train_test_split(\n",
    "    ds_df_train,\n",
    "    test_size = run['dataset']['split_val'],\n",
    "    stratify = ds_df_train[[ datasets[ run['dataset']['source'] ].col_label ]],\n",
    "    random_state = run['dataset']['seed_split_val'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e04a392",
   "metadata": {},
   "source": [
    "### Input Data Pipeline Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57fab483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(\n",
    "    filename,\n",
    "):\n",
    "    img_raw = tf.io.read_file( filename )\n",
    "    img_tensor = tf.image.decode_image(\n",
    "        img_raw,\n",
    "        dtype = tf.dtypes.float32,\n",
    "        channels = 3,\n",
    "        expand_animations = False,\n",
    "    )\n",
    "    return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e9a3cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(\n",
    "    img_tensor,\n",
    "    input_dim,\n",
    "):\n",
    "    return tf.image.resize(\n",
    "        img_tensor,\n",
    "        [ input_dim, input_dim ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2635233b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(\n",
    "    img_tensor,\n",
    "    preprocessor,\n",
    "):\n",
    "    return preprocessor( img_tensor )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e8a276f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_label_encoder( label, mapping ):\n",
    "    one_hot = label == mapping\n",
    "    label_encoded = tf.argmax( one_hot )\n",
    "    return label_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "848b3561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_label(\n",
    "    label,\n",
    "    label_encoder,\n",
    "):\n",
    "    return label_encoder( label )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6d3c05ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(\n",
    "    img_tensor,\n",
    "    augmentation_func,\n",
    "):\n",
    "    return augmentation_func( img_tensor, training = True )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "21f1d384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation function selection\n",
    "augmentation_functions = [\n",
    "    tf.keras.Sequential( [\n",
    "        tf.keras.layers.RandomFlip( \"horizontal_and_vertical\" ),\n",
    "        tf.keras.layers.RandomRotation( 0.2 ),\n",
    "    ] )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9237d8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set augmentation_func to None if no augmentation is desired\n",
    "# augmentation_func = augmentation_functions[0]\n",
    "augmentation_func = None\n",
    "\n",
    "# Determines if data augmentation should be done in the IDP or in the model\n",
    "# Data augmentation will\n",
    "data_augmentation_in_ds = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0021e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a buffersize equal to the length of the dataset\n",
    "shuffle_buffer_size = int( len( ds_df_train ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9627a264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate and save the shuffle random seed\n",
    "run['dataset']['seed_shuffle'] = tf.random.uniform(\n",
    "    shape = (),\n",
    "    dtype = tf.int64,\n",
    "    maxval = tf.int64.max,\n",
    ").numpy()\n",
    "# make it json serializable...\n",
    "run['dataset']['seed_shuffle'] = int( run['dataset']['seed_shuffle'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "54a0222a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determines if preprocessing should be done in the IDP or in the model\n",
    "preprocessing_in_ds = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ffc84037",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charlescoult/.conda/envs/fungi/lib/python3.10/site-packages/numpy/core/numeric.py:2468: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n"
     ]
    }
   ],
   "source": [
    "# label encoding\n",
    "# (img_tensor_resized_preprocessed, label_encoded)\n",
    "label_encoder = tf.keras.layers.StringLookup(\n",
    "    vocabulary = ds_classes,\n",
    "    # sparse = True,\n",
    "    output_mode = 'one_hot',\n",
    "    num_oov_indices = 0,\n",
    ")\n",
    "\n",
    "def make_idp(\n",
    "    filenames,\n",
    "    labels,\n",
    "    input_dim,\n",
    "    is_training = False,\n",
    "    batch_size = 32,\n",
    "    augmentation_func = None,\n",
    "):\n",
    "    ds = tf.data.Dataset.from_tensor_slices( (\n",
    "        filenames,\n",
    "        labels,\n",
    "    ) )\n",
    "\n",
    "    # if isTraining, shuffle\n",
    "    if ( is_training ):\n",
    "        ds = ds.shuffle(\n",
    "            buffer_size = shuffle_buffer_size,\n",
    "            seed = run['dataset']['seed_shuffle'],\n",
    "        )\n",
    "\n",
    "    # image loading\n",
    "    # (img_tensor, label)\n",
    "    ds = ds.map(\n",
    "        lambda filename, label: (\n",
    "            load_image(filename),\n",
    "            label,\n",
    "        ),\n",
    "        num_parallel_calls = AUTOTUNE,\n",
    "    )\n",
    "\n",
    "    # if isTraining and augmentation_func exists, use data augmentation\n",
    "    if ( is_training and data_augmentation_in_ds and augmentation_func ):\n",
    "        logging.info(\"Adding data augmentation.\")\n",
    "        ds = ds.map(\n",
    "            lambda img_tensor, label: (\n",
    "                data_augmentation(img_tensor, augmentation_func),\n",
    "                label,\n",
    "            ),\n",
    "            num_parallel_calls = AUTOTUNE,\n",
    "        )\n",
    "    \n",
    "    # image resizing\n",
    "    # (img_tensor_resized, label)\n",
    "    ds = ds.map(\n",
    "        lambda img_tensor, label: (\n",
    "            resize( img_tensor, input_dim ),\n",
    "            label,\n",
    "        ),\n",
    "        num_parallel_calls = AUTOTUNE,\n",
    "    )\n",
    "    \n",
    "    # image preprocessing\n",
    "    # (img_tensor_resized_preprocessed, label)\n",
    "    if ( preprocessing_in_ds ):\n",
    "        ds = ds.map(\n",
    "            lambda img_tensor_resized, label: (\n",
    "                preprocessing( img_tensor_resized, base_models[ run['model']['base'] ].preprocessor ),\n",
    "                label,\n",
    "            ),\n",
    "            num_parallel_calls = AUTOTUNE,\n",
    "        )\n",
    "\n",
    "\n",
    "    ds = ds.map(\n",
    "        lambda img_tensor_resized_preprocessed, label: (\n",
    "            img_tensor_resized_preprocessed,\n",
    "            encode_label( label, label_encoder ),\n",
    "            # encode_label( label, lambda x: my_label_encoder( x, ds_classes ) ),\n",
    "        ),\n",
    "        num_parallel_calls = AUTOTUNE,\n",
    "    )\n",
    "\n",
    "    # Batch\n",
    "    ds = ds.batch( batch_size )\n",
    "    \n",
    "    # Prefetch\n",
    "    ds = ds.prefetch( buffer_size = AUTOTUNE )\n",
    "    \n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dbefbe53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/charlescoult/.conda/envs/fungi/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/charlescoult/.conda/envs/fungi/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "# IDP creation\n",
    "ds_idp_train = make_idp(\n",
    "    ds_df_train[ datasets[ run['dataset']['source'] ].col_filename ].values,\n",
    "    ds_df_train[ datasets[ run['dataset']['source'] ].col_label ].values,\n",
    "    input_dim = base_models[ run['model']['base'] ].input_dim,\n",
    "    is_training = True,\n",
    "    batch_size = run['batch_size'],\n",
    "    augmentation_func = augmentation_func if ( augmentation_func ) else None,\n",
    ")\n",
    "\n",
    "ds_idp_val = make_idp(\n",
    "    ds_df_val[ datasets[ run['dataset']['source'] ].col_filename ].values,\n",
    "    ds_df_val[ datasets[ run['dataset']['source'] ].col_label ].values,\n",
    "    input_dim = base_models[ run['model']['base'] ].input_dim,\n",
    "    is_training = False,\n",
    "    batch_size = run['batch_size'],\n",
    "    # turned off by is_training = False anyway...\n",
    "    augmentation_func = None,\n",
    ")\n",
    "\n",
    "ds_idp_test = make_idp(\n",
    "    ds_df_test[ datasets[ run['dataset']['source'] ].col_filename ].values,\n",
    "    ds_df_test[ datasets[ run['dataset']['source'] ].col_label ].values,\n",
    "    input_dim = base_models[ run['model']['base'] ].input_dim,\n",
    "    is_training = False,\n",
    "    batch_size = run['batch_size'],\n",
    "    # turned off by is_training = False anyway...\n",
    "    augmentation_func = None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b2f273df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]], shape=(64, 200), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for el in ds_idp_train.take(1):\n",
    "    print(el[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de845ab",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1aa7788",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9a0c6376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return a name that accurately describes the model building function or\n",
    "# the tfhub model (by url) that was passed\n",
    "def get_model_name( model_handle ):\n",
    "\n",
    "    if callable(model_handle):\n",
    "        return f'keras.applications/{model_handle.__name__}'\n",
    "    else:\n",
    "        split = model_handle.split('/')\n",
    "        return f'tfhub/{split[-5]}.{split[-4]}.{split[-3]}'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3acf9abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize full model\n",
    "with strategy.scope():\n",
    "    full_model = tf.keras.Sequential( name = \"full_model\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ad741a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if preprocessing_in_ds, then input is assumed to be preprocessed correctly from input dataset pipeline (idp)\n",
    "# else, add preprocessing layer to model\n",
    "with strategy.scope():\n",
    "    if ( not preprocessing_in_ds ):\n",
    "        raise Exception('not yet implemented')\n",
    "        full_model.add(\n",
    "\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a91f6bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate base_model layer\n",
    "def gen_base_model_layer(\n",
    "    name,\n",
    "    source,\n",
    "    input_dim,\n",
    "    trainable = False,\n",
    "):\n",
    "    # If model_handle is a model building function, use that function\n",
    "    if callable( source ):\n",
    "        base_model = source(\n",
    "            include_top = False,\n",
    "            input_shape = ( input_dim, input_dim ) + (3,),\n",
    "            weights = 'imagenet',\n",
    "            # pooling = 'avg',\n",
    "        )\n",
    "\n",
    "    # otherwise build a layer from the tfhub url that was passed as a string\n",
    "    else:\n",
    "        base_model = hub.KerasLayer(\n",
    "            source,\n",
    "            input_shape = ( input_dim, input_dim ) + (3,),\n",
    "            name = name,\n",
    "        )\n",
    "    \n",
    "    base_model.trainable = trainable\n",
    "\n",
    "    return base_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fa51aae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n",
      "INFO:absl:Using /tmp/tfhub_modules to cache modules.\n"
     ]
    }
   ],
   "source": [
    "# Add base model to full_model\n",
    "with strategy.scope():\n",
    "    full_model.add( gen_base_model_layer(\n",
    "        name = get_model_name( base_models[ run['model']['base'] ].source ),\n",
    "        source = base_models[ run['model']['base'] ].source,\n",
    "        input_dim = base_models[ run['model']['base'] ].input_dim,\n",
    "        trainable = True,\n",
    "    ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "48d708e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate classifier\n",
    "def gen_classifier_model_layer(\n",
    "    num_classes,\n",
    "    dropout,\n",
    "    add_softmax = False,\n",
    "):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(\n",
    "        layers.Dense(\n",
    "            num_classes,\n",
    "            # activation = 'softmax',\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.add(\n",
    "        layers.Dropout(dropout),\n",
    "    )\n",
    "\n",
    "    if ( add_softmax ):\n",
    "        model.add(\n",
    "            layers.Activation(\"softmax\", dtype=\"float32\"),\n",
    "        )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6aa4dddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "run['model']['classifier']['output_logits'] = True\n",
    "# Add classifier model to full_model\n",
    "# TODO allow selection between different classification models\n",
    "with strategy.scope():\n",
    "    full_model.add( gen_classifier_model_layer(\n",
    "        num_classes = len( ds_classes ),\n",
    "        dropout = run['model']['classifier']['dropout'],\n",
    "        add_softmax = not run['model']['classifier']['output_logits'],\n",
    "    ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65bf126",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5b6575",
   "metadata": {},
   "source": [
    "* Note regarding `thawed_base_model_layers` and full model architecture ([reference](https://stackoverflow.com/questions/64227483/what-is-the-right-way-to-gradually-unfreeze-layers-in-neural-network-while-learn))\n",
    "![image](https://i.stack.imgur.com/JLJqv.png)\n",
    "* [Another great reference](https://towardsdatascience.com/transfer-learning-from-pre-trained-models-f2393f124751)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253c44ee",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0881edf",
   "metadata": {},
   "source": [
    "# Training Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ed107505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: allow loading of model weights from previous run\n",
    "load_weights = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b6bce53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "# Sparse vs non-sparse CCE https://www.kaggle.com/general/197993\n",
    "with strategy.scope():\n",
    "    full_model.compile(\n",
    "        optimizer = tf.keras.optimizers.Adam(\n",
    "            learning_rate = run['model']['learning_rate']\n",
    "        ),\n",
    "        # loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        #     from_logits = True,\n",
    "        # ),\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy(\n",
    "            from_logits = run['model']['classifier']['output_logits'],\n",
    "            label_smoothing = run['label_smoothing'],\n",
    "        ),\n",
    "        metrics = [\n",
    "            'accuracy',\n",
    "            tf.keras.metrics.AUC(),\n",
    "            # tf.keras.metrics.SparseCategoricalCrossentropy(),\n",
    "            # tf.keras.metrics.SparseTopKCategoricalAccuracy(\n",
    "            #     k = 3,\n",
    "            #     name = \"Top3\",\n",
    "            # ),\n",
    "            # tf.keras.metrics.SparseTopKCategoricalAccuracy(\n",
    "            #     k = 10,\n",
    "            #     name=\"Top10\",\n",
    "            # ),\n",
    "            # tf.keras.metrics.CategoricalCrossentropy(),            \n",
    "            # tf.keras.metrics.TopKCategoricalAccuracy( k=3, name=\"Top3\" ),\n",
    "            # tf.keras.metrics.TopKCategoricalAccuracy( k=10, name=\"Top10\" ),\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9df29b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard logs\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir = run['path'],\n",
    "    histogram_freq = 1,\n",
    ")\n",
    "\n",
    "# Early stopping\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    # monitor='val_sparse_categorical_accuracy',\n",
    "    monitor = 'val_loss',\n",
    "    verbose = 1,\n",
    "    patience = 5,\n",
    "    min_delta = 0.01,\n",
    "    restore_best_weights = run['callbacks']['early_stopping']['restore_best_weights'],\n",
    "    # mode = 'min', # should be chosen correctly based on monitor value\n",
    ")\n",
    "\n",
    "# Model Checkpoints for saving best model weights\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    os.path.join( run['path'], 'best_model' ),\n",
    "    save_best_only = True,\n",
    "    monitor = 'val_loss',\n",
    "    verbose = 1,\n",
    "    # mode = 'min', # should be chosen correctly based on monitor value\n",
    ")\n",
    "\n",
    "def log_confusion_matrix(epoch, logs):\n",
    "  # Use the model to predict the values from the validation dataset.\n",
    "  test_pred_raw = model.predict(test_images)\n",
    "  test_pred = np.argmax(test_pred_raw, axis=1)\n",
    "\n",
    "  # Calculate the confusion matrix.\n",
    "  cm = sklearn.metrics.confusion_matrix(test_labels, test_pred)\n",
    "  # Log the confusion matrix as an image summary.\n",
    "  figure = plot_confusion_matrix(cm, class_names=class_names)\n",
    "  cm_image = plot_to_image(figure)\n",
    "\n",
    "  # Log the confusion matrix as an image summary.\n",
    "  with file_writer_cm.as_default():\n",
    "    tf.summary.image(\"epoch_confusion_matrix\", cm_image, step=epoch)\n",
    "\n",
    "# Define the per-epoch callback.\n",
    "cm_callback = keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
    "\n",
    "class TimeCallback( tf.keras.callbacks.Callback ):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        metric_name = 'epoch_duration',\n",
    "    ):\n",
    "        self.__epoch_start = None\n",
    "        self.__metric_name = metric_name\n",
    "    \n",
    "    def on_epoch_begin(\n",
    "        self,\n",
    "        epoch,\n",
    "        logs = None,\n",
    "    ):\n",
    "        self.__epoch_start = datetime.datetime.utcnow()\n",
    "        \n",
    "    def on_epoch_end(\n",
    "    ):\n",
    "        logs[ self.__metric_name ] = datetime.datetime.utcnow() - self.__epoch_start\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    tensorboard_callback,\n",
    "    # early_stopping_callback,\n",
    "    model_checkpoint_callback,\n",
    "    cm_callback,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e094001a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"id\": \"2023_03_19-15_07_43\",\n",
      "   \"notebook_ver\": \"0.0.1\",\n",
      "   \"path\": \"/media/data/runs/2023_03_19-15_07_43\",\n",
      "   \"batch_size\": 64,\n",
      "   \"max_epochs\": 50,\n",
      "   \"label_smoothing\": 0.1,\n",
      "   \"model\": {\n",
      "      \"learning_rate\": 0.0001,\n",
      "      \"classifier\": {\n",
      "         \"dropout\": 0.33,\n",
      "         \"output_logits\": true\n",
      "      },\n",
      "      \"base\": \"Inception_v3_iNaturalist\"\n",
      "   },\n",
      "   \"dataset\": {\n",
      "      \"downsample\": \"min\",\n",
      "      \"source\": \"cub\",\n",
      "      \"split_test\": 0.05,\n",
      "      \"split_val\": 0.1,\n",
      "      \"seed_split_test\": 3357302586,\n",
      "      \"seed_split_val\": 3608849373,\n",
      "      \"seed_shuffle\": 7247728688542082922\n",
      "   },\n",
      "   \"callbacks\": {\n",
      "      \"early_stopping\": {\n",
      "         \"restore_best_weights\": true\n",
      "      }\n",
      "   },\n",
      "   \"label_mapping_path\": \"/media/data/runs/2023_03_19-15_07_43/label_mapping.json\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print_run_metadata( run )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "79d7253d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_56896/3436063570.py:32: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->Index(['notebook_ver', 'path', 'label_mapping_path',\n",
      "       'model.classifier.output_logits', 'model.base', 'dataset.downsample',\n",
      "       'dataset.source', 'callbacks.early_stopping.restore_best_weights'],\n",
      "      dtype='object')]\n",
      "\n",
      "  runs_df.to_hdf( runs_hdf_path, runs_hdf_key )\n"
     ]
    }
   ],
   "source": [
    "save_run_metadata( run )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "510fdab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 3.9713 - accuracy: 0.3977 - auc: 0.7668\n",
      "Epoch 1: val_loss improved from inf to 5.63989, saving model to /media/data/runs/2023_03_19-15_07_43/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) tfhub/google.inaturalist.inception_v3_input with unsupported characters which will be renamed to tfhub_google_inaturalist_inception_v3_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 66s 373ms/step - loss: 3.9713 - accuracy: 0.3977 - auc: 0.7668 - val_loss: 5.6399 - val_accuracy: 0.0039 - val_auc: 0.4998\n",
      "Epoch 2/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.7761 - accuracy: 0.6157 - auc: 0.8274\n",
      "Epoch 2: val_loss improved from 5.63989 to 5.61971, saving model to /media/data/runs/2023_03_19-15_07_43/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) tfhub/google.inaturalist.inception_v3_input with unsupported characters which will be renamed to tfhub_google_inaturalist_inception_v3_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 34s 308ms/step - loss: 2.7761 - accuracy: 0.6157 - auc: 0.8274 - val_loss: 5.6197 - val_accuracy: 0.0051 - val_auc: 0.5021\n",
      "Epoch 3/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.6427 - accuracy: 0.6353 - auc: 0.8263\n",
      "Epoch 3: val_loss improved from 5.61971 to 5.57194, saving model to /media/data/runs/2023_03_19-15_07_43/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) tfhub/google.inaturalist.inception_v3_input with unsupported characters which will be renamed to tfhub_google_inaturalist_inception_v3_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 35s 318ms/step - loss: 2.6427 - accuracy: 0.6353 - auc: 0.8263 - val_loss: 5.5719 - val_accuracy: 0.0128 - val_auc: 0.5221\n",
      "Epoch 4/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.5799 - accuracy: 0.6441 - auc: 0.8262\n",
      "Epoch 4: val_loss improved from 5.57194 to 5.47234, saving model to /media/data/runs/2023_03_19-15_07_43/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) tfhub/google.inaturalist.inception_v3_input with unsupported characters which will be renamed to tfhub_google_inaturalist_inception_v3_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 34s 312ms/step - loss: 2.5799 - accuracy: 0.6441 - auc: 0.8262 - val_loss: 5.4723 - val_accuracy: 0.0411 - val_auc: 0.5357\n",
      "Epoch 5/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.4982 - accuracy: 0.6601 - auc: 0.8309\n",
      "Epoch 5: val_loss did not improve from 5.47234\n",
      "110/110 [==============================] - 29s 266ms/step - loss: 2.4982 - accuracy: 0.6601 - auc: 0.8309 - val_loss: 5.4912 - val_accuracy: 0.0308 - val_auc: 0.5269\n",
      "Epoch 6/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.4787 - accuracy: 0.6632 - auc: 0.8305\n",
      "Epoch 6: val_loss improved from 5.47234 to 4.73207, saving model to /media/data/runs/2023_03_19-15_07_43/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) tfhub/google.inaturalist.inception_v3_input with unsupported characters which will be renamed to tfhub_google_inaturalist_inception_v3_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 35s 314ms/step - loss: 2.4787 - accuracy: 0.6632 - auc: 0.8305 - val_loss: 4.7321 - val_accuracy: 0.2182 - val_auc: 0.6547\n",
      "Epoch 7/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.4500 - accuracy: 0.6662 - auc: 0.8321\n",
      "Epoch 7: val_loss did not improve from 4.73207\n",
      "110/110 [==============================] - 30s 268ms/step - loss: 2.4500 - accuracy: 0.6662 - auc: 0.8321 - val_loss: 5.2875 - val_accuracy: 0.0834 - val_auc: 0.5629\n",
      "Epoch 8/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.4063 - accuracy: 0.6789 - auc: 0.8368\n",
      "Epoch 8: val_loss improved from 4.73207 to 4.67492, saving model to /media/data/runs/2023_03_19-15_07_43/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) tfhub/google.inaturalist.inception_v3_input with unsupported characters which will be renamed to tfhub_google_inaturalist_inception_v3_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 35s 316ms/step - loss: 2.4063 - accuracy: 0.6789 - auc: 0.8368 - val_loss: 4.6749 - val_accuracy: 0.2311 - val_auc: 0.6497\n",
      "Epoch 9/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.4508 - accuracy: 0.6638 - auc: 0.8298\n",
      "Epoch 9: val_loss did not improve from 4.67492\n",
      "110/110 [==============================] - 29s 265ms/step - loss: 2.4508 - accuracy: 0.6638 - auc: 0.8298 - val_loss: 5.3697 - val_accuracy: 0.0719 - val_auc: 0.5446\n",
      "Epoch 10/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.4272 - accuracy: 0.6678 - auc: 0.8325\n",
      "Epoch 10: val_loss improved from 4.67492 to 3.90745, saving model to /media/data/runs/2023_03_19-15_07_43/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) tfhub/google.inaturalist.inception_v3_input with unsupported characters which will be renamed to tfhub_google_inaturalist_inception_v3_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 35s 315ms/step - loss: 2.4272 - accuracy: 0.6678 - auc: 0.8325 - val_loss: 3.9074 - val_accuracy: 0.4134 - val_auc: 0.7640\n",
      "Epoch 11/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.3895 - accuracy: 0.6779 - auc: 0.8373\n",
      "Epoch 11: val_loss improved from 3.90745 to 3.87978, saving model to /media/data/runs/2023_03_19-15_07_43/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) tfhub/google.inaturalist.inception_v3_input with unsupported characters which will be renamed to tfhub_google_inaturalist_inception_v3_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 35s 314ms/step - loss: 2.3895 - accuracy: 0.6779 - auc: 0.8373 - val_loss: 3.8798 - val_accuracy: 0.4403 - val_auc: 0.7710\n",
      "Epoch 12/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.4327 - accuracy: 0.6660 - auc: 0.8310\n",
      "Epoch 12: val_loss improved from 3.87978 to 3.12917, saving model to /media/data/runs/2023_03_19-15_07_43/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) tfhub/google.inaturalist.inception_v3_input with unsupported characters which will be renamed to tfhub_google_inaturalist_inception_v3_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 35s 318ms/step - loss: 2.4327 - accuracy: 0.6660 - auc: 0.8310 - val_loss: 3.1292 - val_accuracy: 0.6072 - val_auc: 0.8818\n",
      "Epoch 13/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.4131 - accuracy: 0.6721 - auc: 0.8334\n",
      "Epoch 13: val_loss improved from 3.12917 to 3.12560, saving model to /media/data/runs/2023_03_19-15_07_43/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) tfhub/google.inaturalist.inception_v3_input with unsupported characters which will be renamed to tfhub_google_inaturalist_inception_v3_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 35s 316ms/step - loss: 2.4131 - accuracy: 0.6721 - auc: 0.8334 - val_loss: 3.1256 - val_accuracy: 0.6226 - val_auc: 0.8630\n",
      "Epoch 14/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.4137 - accuracy: 0.6701 - auc: 0.8330\n",
      "Epoch 14: val_loss did not improve from 3.12560\n",
      "110/110 [==============================] - 30s 269ms/step - loss: 2.4137 - accuracy: 0.6701 - auc: 0.8330 - val_loss: 3.5442 - val_accuracy: 0.5507 - val_auc: 0.8353\n",
      "Epoch 15/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.4042 - accuracy: 0.6728 - auc: 0.8341\n",
      "Epoch 15: val_loss improved from 3.12560 to 2.61250, saving model to /media/data/runs/2023_03_19-15_07_43/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) tfhub/google.inaturalist.inception_v3_input with unsupported characters which will be renamed to tfhub_google_inaturalist_inception_v3_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 35s 319ms/step - loss: 2.4042 - accuracy: 0.6728 - auc: 0.8341 - val_loss: 2.6125 - val_accuracy: 0.7535 - val_auc: 0.9292\n",
      "Epoch 16/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.3861 - accuracy: 0.6779 - auc: 0.8363\n",
      "Epoch 16: val_loss improved from 2.61250 to 2.37271, saving model to /media/data/runs/2023_03_19-15_07_43/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) tfhub/google.inaturalist.inception_v3_input with unsupported characters which will be renamed to tfhub_google_inaturalist_inception_v3_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 35s 315ms/step - loss: 2.3861 - accuracy: 0.6779 - auc: 0.8363 - val_loss: 2.3727 - val_accuracy: 0.7831 - val_auc: 0.9578\n",
      "Epoch 17/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.4237 - accuracy: 0.6675 - auc: 0.8310\n",
      "Epoch 17: val_loss did not improve from 2.37271\n",
      "110/110 [==============================] - 30s 269ms/step - loss: 2.4237 - accuracy: 0.6675 - auc: 0.8310 - val_loss: 2.9223 - val_accuracy: 0.6598 - val_auc: 0.9026\n",
      "Epoch 18/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.3853 - accuracy: 0.6775 - auc: 0.8361\n",
      "Epoch 18: val_loss did not improve from 2.37271\n",
      "110/110 [==============================] - 30s 274ms/step - loss: 2.3853 - accuracy: 0.6775 - auc: 0.8361 - val_loss: 3.8290 - val_accuracy: 0.4493 - val_auc: 0.7935\n",
      "Epoch 19/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.4225 - accuracy: 0.6665 - auc: 0.8313\n",
      "Epoch 19: val_loss did not improve from 2.37271\n",
      "110/110 [==============================] - 30s 270ms/step - loss: 2.4225 - accuracy: 0.6665 - auc: 0.8313 - val_loss: 5.6036 - val_accuracy: 0.0051 - val_auc: 0.5102\n",
      "Epoch 20/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.4086 - accuracy: 0.6732 - auc: 0.8367\n",
      "Epoch 20: val_loss did not improve from 2.37271\n",
      "110/110 [==============================] - 30s 268ms/step - loss: 2.4086 - accuracy: 0.6732 - auc: 0.8367 - val_loss: 5.7265 - val_accuracy: 0.0039 - val_auc: 0.5024\n",
      "Epoch 21/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.4924 - accuracy: 0.6622 - auc: 0.8359\n",
      "Epoch 21: val_loss did not improve from 2.37271\n",
      "110/110 [==============================] - 29s 267ms/step - loss: 2.4924 - accuracy: 0.6622 - auc: 0.8359 - val_loss: 5.7986 - val_accuracy: 0.0051 - val_auc: 0.5063\n",
      "Epoch 22/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.5278 - accuracy: 0.6520 - auc: 0.8309\n",
      "Epoch 22: val_loss did not improve from 2.37271\n",
      "110/110 [==============================] - 29s 267ms/step - loss: 2.5278 - accuracy: 0.6520 - auc: 0.8309 - val_loss: 5.6818 - val_accuracy: 0.0103 - val_auc: 0.5070\n",
      "Epoch 23/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.4583 - accuracy: 0.6678 - auc: 0.8342\n",
      "Epoch 23: val_loss did not improve from 2.37271\n",
      "110/110 [==============================] - 29s 265ms/step - loss: 2.4583 - accuracy: 0.6678 - auc: 0.8342 - val_loss: 5.6921 - val_accuracy: 0.0039 - val_auc: 0.5020\n",
      "Epoch 24/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.4211 - accuracy: 0.6718 - auc: 0.8343\n",
      "Epoch 24: val_loss did not improve from 2.37271\n",
      "110/110 [==============================] - 29s 265ms/step - loss: 2.4211 - accuracy: 0.6718 - auc: 0.8343 - val_loss: 3.6318 - val_accuracy: 0.4416 - val_auc: 0.8306\n",
      "Epoch 25/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.3769 - accuracy: 0.6798 - auc: 0.8381\n",
      "Epoch 25: val_loss did not improve from 2.37271\n",
      "110/110 [==============================] - 29s 265ms/step - loss: 2.3769 - accuracy: 0.6798 - auc: 0.8381 - val_loss: 3.1541 - val_accuracy: 0.5635 - val_auc: 0.8735\n",
      "Epoch 26/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.3772 - accuracy: 0.6767 - auc: 0.8368\n",
      "Epoch 26: val_loss improved from 2.37271 to 2.34353, saving model to /media/data/runs/2023_03_19-15_07_43/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) tfhub/google.inaturalist.inception_v3_input with unsupported characters which will be renamed to tfhub_google_inaturalist_inception_v3_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 34s 312ms/step - loss: 2.3772 - accuracy: 0.6767 - auc: 0.8368 - val_loss: 2.3435 - val_accuracy: 0.7574 - val_auc: 0.9495\n",
      "Epoch 27/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.3911 - accuracy: 0.6727 - auc: 0.8343\n",
      "Epoch 27: val_loss improved from 2.34353 to 1.97662, saving model to /media/data/runs/2023_03_19-15_07_43/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) tfhub/google.inaturalist.inception_v3_input with unsupported characters which will be renamed to tfhub_google_inaturalist_inception_v3_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 34s 308ms/step - loss: 2.3911 - accuracy: 0.6727 - auc: 0.8343 - val_loss: 1.9766 - val_accuracy: 0.8280 - val_auc: 0.9707\n",
      "Epoch 28/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.3662 - accuracy: 0.6792 - auc: 0.8374\n",
      "Epoch 28: val_loss improved from 1.97662 to 1.86138, saving model to /media/data/runs/2023_03_19-15_07_43/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) tfhub/google.inaturalist.inception_v3_input with unsupported characters which will be renamed to tfhub_google_inaturalist_inception_v3_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 34s 312ms/step - loss: 2.3662 - accuracy: 0.6792 - auc: 0.8374 - val_loss: 1.8614 - val_accuracy: 0.8575 - val_auc: 0.9742\n",
      "Epoch 29/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.3619 - accuracy: 0.6791 - auc: 0.8378\n",
      "Epoch 29: val_loss did not improve from 1.86138\n",
      "110/110 [==============================] - 29s 264ms/step - loss: 2.3619 - accuracy: 0.6791 - auc: 0.8378 - val_loss: 2.3528 - val_accuracy: 0.7766 - val_auc: 0.9473\n",
      "Epoch 30/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.3879 - accuracy: 0.6721 - auc: 0.8338\n",
      "Epoch 30: val_loss did not improve from 1.86138\n",
      "110/110 [==============================] - 29s 267ms/step - loss: 2.3879 - accuracy: 0.6721 - auc: 0.8338 - val_loss: 2.1319 - val_accuracy: 0.8049 - val_auc: 0.9591\n",
      "Epoch 31/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.4003 - accuracy: 0.6687 - auc: 0.8318\n",
      "Epoch 31: val_loss did not improve from 1.86138\n",
      "110/110 [==============================] - 29s 261ms/step - loss: 2.4003 - accuracy: 0.6687 - auc: 0.8318 - val_loss: 1.9090 - val_accuracy: 0.8537 - val_auc: 0.9690\n",
      "Epoch 32/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.3563 - accuracy: 0.6811 - auc: 0.8377\n",
      "Epoch 32: val_loss did not improve from 1.86138\n",
      "110/110 [==============================] - 29s 260ms/step - loss: 2.3563 - accuracy: 0.6811 - auc: 0.8377 - val_loss: 1.9103 - val_accuracy: 0.8472 - val_auc: 0.9684\n",
      "Epoch 33/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.3649 - accuracy: 0.6778 - auc: 0.8364\n",
      "Epoch 33: val_loss did not improve from 1.86138\n",
      "110/110 [==============================] - 28s 259ms/step - loss: 2.3649 - accuracy: 0.6778 - auc: 0.8364 - val_loss: 2.0142 - val_accuracy: 0.8344 - val_auc: 0.9677\n",
      "Epoch 34/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.3818 - accuracy: 0.6717 - auc: 0.8337\n",
      "Epoch 34: val_loss did not improve from 1.86138\n",
      "110/110 [==============================] - 28s 259ms/step - loss: 2.3818 - accuracy: 0.6717 - auc: 0.8337 - val_loss: 1.8989 - val_accuracy: 0.8562 - val_auc: 0.9679\n",
      "Epoch 35/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.3781 - accuracy: 0.6724 - auc: 0.8341\n",
      "Epoch 35: val_loss did not improve from 1.86138\n",
      "110/110 [==============================] - 29s 262ms/step - loss: 2.3781 - accuracy: 0.6724 - auc: 0.8341 - val_loss: 1.9990 - val_accuracy: 0.8383 - val_auc: 0.9678\n",
      "Epoch 36/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.3503 - accuracy: 0.6799 - auc: 0.8377\n",
      "Epoch 36: val_loss did not improve from 1.86138\n",
      "110/110 [==============================] - 29s 262ms/step - loss: 2.3503 - accuracy: 0.6799 - auc: 0.8377 - val_loss: 1.9986 - val_accuracy: 0.8344 - val_auc: 0.9677\n",
      "Epoch 37/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.3651 - accuracy: 0.6765 - auc: 0.8355\n",
      "Epoch 37: val_loss did not improve from 1.86138\n",
      "110/110 [==============================] - 28s 257ms/step - loss: 2.3651 - accuracy: 0.6765 - auc: 0.8355 - val_loss: 1.9498 - val_accuracy: 0.8408 - val_auc: 0.9666\n",
      "Epoch 38/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.3786 - accuracy: 0.6709 - auc: 0.8334\n",
      "Epoch 38: val_loss did not improve from 1.86138\n",
      "110/110 [==============================] - 29s 262ms/step - loss: 2.3786 - accuracy: 0.6709 - auc: 0.8334 - val_loss: 2.0078 - val_accuracy: 0.8460 - val_auc: 0.9665\n",
      "Epoch 39/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.3884 - accuracy: 0.6687 - auc: 0.8318\n",
      "Epoch 39: val_loss did not improve from 1.86138\n",
      "110/110 [==============================] - 29s 260ms/step - loss: 2.3884 - accuracy: 0.6687 - auc: 0.8318 - val_loss: 2.0341 - val_accuracy: 0.8254 - val_auc: 0.9639\n",
      "Epoch 40/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.3581 - accuracy: 0.6755 - auc: 0.8358\n",
      "Epoch 40: val_loss did not improve from 1.86138\n",
      "110/110 [==============================] - 28s 257ms/step - loss: 2.3581 - accuracy: 0.6755 - auc: 0.8358 - val_loss: 2.1331 - val_accuracy: 0.8177 - val_auc: 0.9580\n",
      "Epoch 41/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.3679 - accuracy: 0.6737 - auc: 0.8344\n",
      "Epoch 41: val_loss did not improve from 1.86138\n",
      "110/110 [==============================] - 29s 261ms/step - loss: 2.3679 - accuracy: 0.6737 - auc: 0.8344 - val_loss: 2.4030 - val_accuracy: 0.7754 - val_auc: 0.9398\n",
      "Epoch 42/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.3085 - accuracy: 0.6901 - auc: 0.8422\n",
      "Epoch 42: val_loss did not improve from 1.86138\n",
      "110/110 [==============================] - 28s 259ms/step - loss: 2.3085 - accuracy: 0.6901 - auc: 0.8422 - val_loss: 2.0703 - val_accuracy: 0.8318 - val_auc: 0.9658\n",
      "Epoch 43/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.3280 - accuracy: 0.6835 - auc: 0.8395\n",
      "Epoch 43: val_loss did not improve from 1.86138\n",
      "110/110 [==============================] - 28s 259ms/step - loss: 2.3280 - accuracy: 0.6835 - auc: 0.8395 - val_loss: 1.9966 - val_accuracy: 0.8447 - val_auc: 0.9665\n",
      "Epoch 44/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.3485 - accuracy: 0.6782 - auc: 0.8362\n",
      "Epoch 44: val_loss did not improve from 1.86138\n",
      "110/110 [==============================] - 29s 262ms/step - loss: 2.3485 - accuracy: 0.6782 - auc: 0.8362 - val_loss: 2.6568 - val_accuracy: 0.7227 - val_auc: 0.9159\n",
      "Epoch 45/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.3738 - accuracy: 0.6718 - auc: 0.8327\n",
      "Epoch 45: val_loss did not improve from 1.86138\n",
      "110/110 [==============================] - 29s 261ms/step - loss: 2.3738 - accuracy: 0.6718 - auc: 0.8327 - val_loss: 4.5685 - val_accuracy: 0.3004 - val_auc: 0.6884\n",
      "Epoch 46/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.3245 - accuracy: 0.6828 - auc: 0.8393\n",
      "Epoch 46: val_loss did not improve from 1.86138\n",
      "110/110 [==============================] - 29s 261ms/step - loss: 2.3245 - accuracy: 0.6828 - auc: 0.8393 - val_loss: 2.5048 - val_accuracy: 0.7343 - val_auc: 0.9301\n",
      "Epoch 47/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.3869 - accuracy: 0.6684 - auc: 0.8324\n",
      "Epoch 47: val_loss did not improve from 1.86138\n",
      "110/110 [==============================] - 28s 259ms/step - loss: 2.3869 - accuracy: 0.6684 - auc: 0.8324 - val_loss: 5.5532 - val_accuracy: 0.0026 - val_auc: 0.5033\n",
      "Epoch 48/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.5901 - accuracy: 0.6386 - auc: 0.8330\n",
      "Epoch 48: val_loss did not improve from 1.86138\n",
      "110/110 [==============================] - 29s 265ms/step - loss: 2.5901 - accuracy: 0.6386 - auc: 0.8330 - val_loss: 5.6222 - val_accuracy: 0.0026 - val_auc: 0.5024\n",
      "Epoch 49/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.4863 - accuracy: 0.6595 - auc: 0.8340\n",
      "Epoch 49: val_loss did not improve from 1.86138\n",
      "110/110 [==============================] - 29s 260ms/step - loss: 2.4863 - accuracy: 0.6595 - auc: 0.8340 - val_loss: 5.5258 - val_accuracy: 0.0167 - val_auc: 0.5250\n",
      "Epoch 50/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 2.4051 - accuracy: 0.6709 - auc: 0.8350\n",
      "Epoch 50: val_loss did not improve from 1.86138\n",
      "110/110 [==============================] - 29s 265ms/step - loss: 2.4051 - accuracy: 0.6709 - auc: 0.8350 - val_loss: 5.2081 - val_accuracy: 0.0822 - val_auc: 0.6115\n",
      "Completed.\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "timer['train_start'] = time.perf_counter()\n",
    "\n",
    "try:\n",
    "    with strategy.scope():\n",
    "        history = full_model.fit(\n",
    "            ds_idp_train,\n",
    "            validation_data = ds_idp_val,\n",
    "            epochs = run['max_epochs'],\n",
    "            callbacks = callbacks,\n",
    "            # validation_freq=2,\n",
    "        )\n",
    "except KeyboardInterrupt:\n",
    "    print('\\n\\nInterrupted...')\n",
    "    # run['interrupted'] = True\n",
    "else:\n",
    "    print('Completed.')\n",
    "    # run['interrupted'] = False\n",
    "    \n",
    "timer['train_end'] = time.perf_counter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "89820f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1567.0440421189996\n"
     ]
    }
   ],
   "source": [
    "run['time'] = timer['train_end'] - timer['train_start']\n",
    "print(run['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "91731c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_56896/3436063570.py:32: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->Index(['notebook_ver', 'path', 'label_mapping_path',\n",
      "       'model.classifier.output_logits', 'model.base', 'dataset.downsample',\n",
      "       'dataset.source', 'callbacks.early_stopping.restore_best_weights'],\n",
      "      dtype='object')]\n",
      "\n",
      "  runs_df.to_hdf( runs_hdf_path, runs_hdf_key )\n"
     ]
    }
   ],
   "source": [
    "save_run_metadata( run )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "926ab664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"id\": \"2023_03_19-15_07_43\",\n",
      "   \"notebook_ver\": \"0.0.1\",\n",
      "   \"path\": \"/media/data/runs/2023_03_19-15_07_43\",\n",
      "   \"batch_size\": 64,\n",
      "   \"max_epochs\": 50,\n",
      "   \"label_smoothing\": 0.1,\n",
      "   \"model\": {\n",
      "      \"learning_rate\": 0.0001,\n",
      "      \"classifier\": {\n",
      "         \"dropout\": 0.33,\n",
      "         \"output_logits\": true\n",
      "      },\n",
      "      \"base\": \"Inception_v3_iNaturalist\"\n",
      "   },\n",
      "   \"dataset\": {\n",
      "      \"downsample\": \"min\",\n",
      "      \"source\": \"cub\",\n",
      "      \"split_test\": 0.05,\n",
      "      \"split_val\": 0.1,\n",
      "      \"seed_split_test\": 3357302586,\n",
      "      \"seed_split_val\": 3608849373,\n",
      "      \"seed_shuffle\": 7247728688542082922\n",
      "   },\n",
      "   \"callbacks\": {\n",
      "      \"early_stopping\": {\n",
      "         \"restore_best_weights\": true\n",
      "      }\n",
      "   },\n",
      "   \"label_mapping_path\": \"/media/data/runs/2023_03_19-15_07_43/label_mapping.json\",\n",
      "   \"time\": 1567.0440421189996\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print_run_metadata( run )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6a14f215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( history.epoch )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48acedd4",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "47ca2024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(410, 200)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels = np.concatenate([y for x, y in ds_idp_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ee6236de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 62ms/step\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    predictions = full_model.predict(\n",
    "        ds_idp_test,\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a8c6d743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.38747343,  0.08082731,  1.1972896 , ..., -0.89137113,\n",
       "         0.03417831, -0.6820032 ],\n",
       "       [-0.5490457 , -0.3088045 ,  0.6963509 , ..., -0.950576  ,\n",
       "        -0.4027964 , -0.68070376],\n",
       "       [-0.7585014 , -0.30991977,  0.86308795, ..., -1.0244632 ,\n",
       "        -0.5560531 , -0.5212998 ],\n",
       "       ...,\n",
       "       [-0.47741184, -0.7980513 ,  0.11648276, ..., -1.0778359 ,\n",
       "        -0.38598242, -0.72817343],\n",
       "       [-0.2950197 , -0.57643265, -0.00526678, ..., -0.9619147 ,\n",
       "        -0.1638769 , -0.02682862],\n",
       "       [-0.12430269, -0.42841172,  0.6732496 , ..., -0.6958899 ,\n",
       "         0.06572216, -0.41389707]], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "01c614ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(410, 200)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "68d4db1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.7544053"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "60fce76a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.7958875"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a5d4f38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f8812e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(410, 200)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c4aef56b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6ff44aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "078e2d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2,  70,  70,  85,   2,   2, 170,   2,   2,   2,  29,   2,   2,\n",
       "         2,   2,  21,   2,   2,   2, 156,  86, 174, 123,   4,   2,   2,\n",
       "       142, 160,   2,  70,  94, 199, 179,   2,  70,  70,   2,  70,   2,\n",
       "         2,  22, 142, 127, 156, 138,   2,  70, 168,   2,   2,   2,   2,\n",
       "         2,   2,   2, 140,   2,   2,   2, 140, 125,   2,  70,  22,   2,\n",
       "        70,  70,   2,   2,   2, 168,  21,   2,   2,  22,   2,   2,   2,\n",
       "         2, 142,  21,  70,  70,  85,   2,  39,  19,  70, 170,  21,   2,\n",
       "       142, 156, 135,   2,  22,   9,   2,  21,   2,  11,   2,  70,   2,\n",
       "        70,   2,  21,   2,   2,  19,   2,   2,  61,  21,   2,   2, 140,\n",
       "         2,   2,  85, 143,   2,   2,  85, 104,  70, 174,   2,   2,   2,\n",
       "         2,  88,  70,  70,   2, 143, 176,   2,  70,  25, 140,  61,   2,\n",
       "        61,   2,   2,  15,   4,   2,  98,   2,  70,  70,   2, 170,  42,\n",
       "        21,  21,   2, 127,  21,   2,  19,  21,   2,  22, 133,  21,   2,\n",
       "        21,  70,  21,   2,  21, 188, 102,   2,   2,  21,  70, 138,   2,\n",
       "         2, 125,  47,  70,  21,  62,  22,  39,   2, 127, 170,  70,  21,\n",
       "        21,  21,   2,  41,  21, 125,   2, 174,  48,  21,  48,  21, 174,\n",
       "        21,  21,  70,   2,   2,  85,   2,   2, 140,  97,   2, 174, 174,\n",
       "        39,   2,   2, 138,  70,   2,   2, 161,   2,  70, 174,  85,  70,\n",
       "         2, 158,   2,   2, 138,  62,  21,  21,   2,   2,   2,   2,  70,\n",
       "        22,   2, 174,   2,  21,   2,   2,   2,  70,   2,  85, 168, 151,\n",
       "         2,  11, 123,  21, 102, 158,   2,   2,   2, 142,   2,   2, 174,\n",
       "         2,  42,   2,  70,  70,   2,  85,  70,  41,   2,  70,  21,   2,\n",
       "         2,   2,   2,   2, 102,  21,  97,   2,   2, 102,   2,  21,   2,\n",
       "         2,   2,   2,  70, 144,  97,   2,  61,   2,   2,  42,   2,   2,\n",
       "        70,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,  70,   2,\n",
       "       102, 137,   2,   9,   2,  70,   2,   2,   2, 174,  70,  94,  22,\n",
       "        70,   2,   2,  21,   2,   2,   2, 199,   2,  70,  21,  70, 140,\n",
       "        70,   4, 134,   2,  21,  21,   2,   2,  70,   2,  70,   2,  70,\n",
       "        70,   2,   2,   2,   4,   2,   2,   2, 174,  22,  70,  85,   2,\n",
       "         2,  70, 174,  70,   2,   4,  70,   2,   2, 102, 123,   2, 170,\n",
       "         2,   2,   2,  70,   2,  21,   2,   2,  70,  22,   2,  85, 174,\n",
       "         2,   2,   2,  70,  15,  21,   2])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax( predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f7e2ae62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 27, 122,  99,  32,  57, 136, 173, 189,  59,  44, 190, 128,  68,\n",
       "        67,  64,  53, 135,  99,  79, 179,  86,  84, 121, 150,   1,  73,\n",
       "        60, 175, 193, 145,  94,  19, 179,  57, 147,  40,   1, 134, 182,\n",
       "       114,  53,  60, 132, 168,  25,  29, 185,  17,   2, 100, 121,  23,\n",
       "        35, 104,  12,  66,  83, 105, 107,  50, 191, 137, 109,  51, 143,\n",
       "       124, 170,  43,  21,  32, 168,  69, 149,  16, 197,  78, 108,  18,\n",
       "        80,  52, 181,  10,  67, 188,  20, 166, 167, 195, 173, 165, 105,\n",
       "        50,  46, 196, 159,  36,  96,  95,  21,  98, 176, 152, 146, 139,\n",
       "        43,  10,  97, 110,  47,  46, 158,  40, 112,  48, 124, 192, 140,\n",
       "        27, 126,  85, 145,  88,  86,  34, 128, 178, 153,  63,   7,   2,\n",
       "       164,  88,  85, 113,  74, 143, 162, 165,  56,  25,  56,   9, 153,\n",
       "        65,   3, 111,  15, 191, 107,   7,  33, 115,  37,  74, 120, 169,\n",
       "       157,  26,  14, 180, 108,  43, 161,  54, 110,  97, 133,  69, 190,\n",
       "        22,  11, 116,  66,  65, 188,  91,  72,  63, 141,  31,  16, 118,\n",
       "         4, 125,  47, 172,  68,  71,  89,  37, 100, 132, 155, 189,  26,\n",
       "        31,  36,   6,  41,  75, 115,  38, 160,  72, 106,  22, 102, 169,\n",
       "       156, 180, 149,  61, 131,  93,  14, 148, 140, 171,   0, 174, 125,\n",
       "        42, 164,  23, 138, 120, 146, 183, 161,  44,  28,  30, 163, 130,\n",
       "       187, 158,  17,  83, 138,  75,  20, 127, 198,  71, 183,  24, 123,\n",
       "       104, 177, 170,  93, 147, 142, 154, 117,  76, 119, 109, 175, 151,\n",
       "       129,  11, 123,  54,  81,  80, 190, 112, 193,  49,  78, 196, 178,\n",
       "        13,  42,  73, 166, 184,  96,  45, 111,  41,  82,  18, 171, 186,\n",
       "        45,  39, 141,  77,  84, 194, 199,  90, 106,  15,  82, 163,   5,\n",
       "        51, 150,  79, 130,  58,  76,  61,  30,   0, 103,  38,  92, 126,\n",
       "        70,  55,  98,   8, 152,  62,  29, 119, 172, 198, 119, 117,   5,\n",
       "        64, 137,   3,   9, 136, 156,  24,  34,   8, 101, 186,  94, 187,\n",
       "        95,  52, 197, 127,  96, 192, 151, 199,  62, 174, 155, 176, 177,\n",
       "        35,   4, 134,  81, 122,  31, 184, 131, 154, 101, 113,  58,  70,\n",
       "       103,  13,  77,  91,   6, 144,  48,  90, 167, 160, 182, 157,  28,\n",
       "       114,  39,  19, 135, 116,  49,  57, 170, 185, 148,  17,  12, 132,\n",
       "        59, 194, 129, 195,  55, 159, 162,  33, 144, 133, 118,  89, 181,\n",
       "        87,  92, 142,  87, 139, 169, 102])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax( test_labels, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "20a6bc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = tf.math.confusion_matrix(\n",
    "    np.argmax( test_labels, axis=1),\n",
    "    np.argmax( predictions, axis=1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba8cf32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-fungi]",
   "language": "python",
   "name": "conda-env-.conda-fungi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
