{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "518a0c58",
   "metadata": {},
   "source": [
    "# Model Generation for GBIF Fungi Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbc8a5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_ver = \"0.0.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b411778a",
   "metadata": {},
   "source": [
    "## References\n",
    "* [Transfer Learning with Hub](https://www.tensorflow.org/tutorials/images/transfer_learning_with_hub)\n",
    "* [`tf.data`: Build TensorFlow input pipelines](https://www.tensorflow.org/guide/data?hl=en)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbff1eb9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a285c8a1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2c0f4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "from keras.utils.layer_utils import count_params\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "import logging\n",
    "\n",
    "# Set logging to output INFO level to standard output\n",
    "logging.basicConfig(level=os.environ.get(\"LOGLEVEL\", \"INFO\"))\n",
    "\n",
    "# Set tf logging level to WARN\n",
    "tf.get_logger().setLevel( 'WARN' )\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a639289",
   "metadata": {},
   "source": [
    "### Limit GPU memory allocation\n",
    "[Limiting GPU Memory Growth](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16845159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_memory_growth(limit=True):\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            # Currently, memory growth needs to be the same across GPUs\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, limit)\n",
    "            logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "        except RuntimeError as e:\n",
    "            # Memory growth must be set before GPUs have been initialized\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10a47939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "limit_memory_growth()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106e1972",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c19476",
   "metadata": {},
   "source": [
    "## Runs dataframe\n",
    "Keeps track of all runs performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60bdfc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_dir = '/media/data/runs'\n",
    "runs_hdf = 'runs.h5'\n",
    "runs_hdf_key = 'runs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce638f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will overwrite existing run in dataframe with the same id\n",
    "# - allows updating as we go\n",
    "def save_run_metadata(\n",
    "    run,\n",
    "    index = 'id',\n",
    "):\n",
    "    # create df from run using json_normalize to flatten dict\n",
    "    run_df = pd.json_normalize( run )\n",
    "    run_df = run_df.set_index( index )\n",
    "\n",
    "    # create runs_df if it doesn't exist\n",
    "    runs_hdf_path = os.path.join( runs_dir, runs_hdf )\n",
    "    if ( not os.path.isfile( runs_hdf_path ) ):\n",
    "        pd.DataFrame().to_hdf( runs_hdf_path, runs_hdf_key )\n",
    "    \n",
    "    # read in the runs_hdf\n",
    "    runs_df = pd.read_hdf(\n",
    "        runs_hdf_path,\n",
    "        runs_hdf_key,\n",
    "    )\n",
    "    \n",
    "    # If a row for this run already exists, remove it\n",
    "    if ( run[ index ] in runs_df.index ):\n",
    "        runs_df = runs_df.drop( run[ index ] )\n",
    " \n",
    "    # Add the updated data\n",
    "    runs_df = pd.concat(\n",
    "        [ runs_df, run_df ],\n",
    "    )\n",
    "    \n",
    "    # save to file\n",
    "    runs_df.to_hdf( runs_hdf_path, runs_hdf_key )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d457167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_run_metadata( run ):\n",
    "    print( json.dumps( run, indent = 3 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2704ae3",
   "metadata": {},
   "source": [
    "## Run Identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4494ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timestamp():\n",
    "    return datetime.datetime.now().strftime('%Y_%m_%d-%H_%M_%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d702f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = {}\n",
    "run['id'] = get_timestamp()\n",
    "run['notebook_ver'] = notebook_ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7603b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/data/runs/2023_03_19-13_25_06'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This run's path\n",
    "run['path'] = os.path.join( runs_dir, str(run['id']) )\n",
    "run['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37f84a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (os.path.exists( run['path'] )):\n",
    "    print(\"Run path already exists!!\")\n",
    "    print(\" Overwriting: %s\" % run['path'])\n",
    "else:\n",
    "    os.makedirs( run['path'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c4f2cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"id\": \"2023_03_19-13_25_06\",\n",
      "   \"notebook_ver\": \"0.0.1\",\n",
      "   \"path\": \"/media/data/runs/2023_03_19-13_25_06\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print_run_metadata( run )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3804c4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_run_metadata( run )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53c36c8",
   "metadata": {},
   "source": [
    "### Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eac14cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "run['batch_size'] = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65adc8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "run['model'] = {}\n",
    "run['model']['classifier'] = {}\n",
    "run['model']['classifier']['dropout'] = 0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d63cd5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets minimum # of samples per dataset for downsampling\n",
    "run['dataset'] = {}\n",
    "# run['dataset']['downsample'] = None\n",
    "run['dataset']['downsample'] = 'min'\n",
    "# run['dataset']['downsample'] = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6595e67a",
   "metadata": {},
   "source": [
    "### Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e9b5d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "timer = {}\n",
    "timer['start'] = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae653da",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3105e4c2",
   "metadata": {},
   "source": [
    "## Define Model Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c66022f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        source,\n",
    "        input_dim,\n",
    "        preprocessor,\n",
    "    ):\n",
    "        self.source = source\n",
    "        self.input_dim = input_dim\n",
    "        self.preprocessor = preprocessor\n",
    "    \n",
    "base_models = {\n",
    "    'MobileNet_v2': BaseModel(\n",
    "        source = 'https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4',\n",
    "        input_dim = 224,\n",
    "        # https://www.tensorflow.org/hub/common_signatures/images#input\n",
    "        # The inputs pixel values are scaled between -1 and 1, sample-wise.\n",
    "        preprocessor = tf.keras.applications.mobilenet_v2.preprocess_input,\n",
    "    ),\n",
    "\n",
    "    'Inception_v3': BaseModel(\n",
    "        source = 'https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/4',\n",
    "        input_dim = 299,\n",
    "        # The inputs pixel values are scaled between -1 and 1, sample-wise.\n",
    "        preprocessor = tf.keras.applications.inception_v3.preprocess_input,\n",
    "    ),\n",
    "\n",
    "    'Inception_v3_iNaturalist': BaseModel(\n",
    "        source = 'https://tfhub.dev/google/inaturalist/inception_v3/feature_vector/5',\n",
    "        input_dim = 299,\n",
    "        # The inputs pixel values are scaled between -1 and 1, sample-wise.\n",
    "        preprocessor = tf.keras.applications.inception_v3.preprocess_input,\n",
    "    ),\n",
    "\n",
    "    'Xception': BaseModel(\n",
    "        source = tf.keras.applications.Xception,\n",
    "        input_dim = 299,\n",
    "        # The inputs pixel values are scaled between -1 and 1, sample-wise.\n",
    "        preprocessor = tf.keras.applications.xception.preprocess_input,\n",
    "    ),\n",
    "\n",
    "    'ResNet101': BaseModel(\n",
    "        source = tf.keras.applications.resnet.ResNet101,\n",
    "        input_dim = 224,\n",
    "        preprocessor = tf.keras.applications.resnet50.preprocess_input,\n",
    "    ),\n",
    "\n",
    "    'ResNet50': BaseModel(\n",
    "        source = tf.keras.applications.ResNet50,\n",
    "        input_dim = 224,\n",
    "        preprocessor = tf.keras.applications.resnet50.preprocess_input,\n",
    "    ),\n",
    "\n",
    "    'Inception_ResNet_v2': BaseModel(\n",
    "        source = tf.keras.applications.InceptionResNetV2,\n",
    "        input_dim = 299,\n",
    "        preprocessor = tf.keras.applications.inception_resnet_v2.preprocess_input,\n",
    "    ),\n",
    "\n",
    "    'EfficientNet_v2': BaseModel(\n",
    "        source = tf.keras.applications.efficientnet_v2.EfficientNetV2B0,\n",
    "        input_dim = 224,\n",
    "        # The preprocessing logic has been included in the EfficientNetV2\n",
    "        # model implementation. Users are no longer required to call this\n",
    "        # method to normalize the input data. This method does nothing and\n",
    "        # only kept as a placeholder to align the API surface between old\n",
    "        # and new version of model.\n",
    "        preprocessor = tf.keras.applications.efficientnet_v2.preprocess_input,\n",
    "    ),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbef9abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "run['model']['base'] = 'Inception_v3_iNaturalist'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b5b5ac",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf8d406",
   "metadata": {},
   "source": [
    "## Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15af0de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetHDFSource:\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        path,\n",
    "        key,\n",
    "        col_filename = 'filename',\n",
    "        col_label = 'label',\n",
    "    ):\n",
    "        self.path = path\n",
    "        self.key = key\n",
    "        self.col_filename = col_filename\n",
    "        self.col_label = col_label\n",
    "\n",
    "datasets = {\n",
    "    'gbif': DatasetHDFSource(\n",
    "        '/media/data/gbif/clean_data.h5',\n",
    "        'media_merged_filtered-by-species_350pt',\n",
    "        col_label = 'acceptedScientificName',\n",
    "    ),\n",
    "    'cub': DatasetHDFSource(\n",
    "        '/media/data/cub/cub.h5',\n",
    "        'cub',\n",
    "        col_filename = 'file_path',\n",
    "        col_label = 'class_name',\n",
    "    ),\n",
    "}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b652b376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run['dataset']['source'] = 'gbif'\n",
    "run['dataset']['source'] = 'cub'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12133130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in source dataframe\n",
    "ds_df = pd.read_hdf(\n",
    "    datasets[ run['dataset']['source'] ].path,\n",
    "    datasets[ run['dataset']['source'] ].key,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb506886",
   "metadata": {},
   "source": [
    "### Dataset Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4608af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label count: 200\n",
      "Datapoint count: 11788\n"
     ]
    }
   ],
   "source": [
    "ds_classes = ds_df[ datasets[ run['dataset']['source'] ].col_label ].unique().tolist()\n",
    "print('Label count: %d' % len(ds_classes))\n",
    "print('Datapoint count: %d' % len(ds_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c17dbad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_label_mapping(\n",
    "    label_mapping,\n",
    "    file_path = './label_mapping.json',\n",
    "):\n",
    "    with open( file_path, 'w' ) as f:\n",
    "        json.dump( label_mapping, f, indent = 3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92876643",
   "metadata": {},
   "outputs": [],
   "source": [
    "run['label_mapping_path'] = os.path.join( run['path'], 'label_mapping.json' )\n",
    "save_label_mapping(\n",
    "    ds_classes,\n",
    "    file_path = run['label_mapping_path'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "828f1236",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_df_label_vc = ds_df[ datasets[ run['dataset']['source'] ].col_label ].value_counts()\n",
    "ds_df_label_vc = ds_df_label_vc.sort_values( ascending = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a9e3c4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Black footed Albatross    60\n",
       "Red eyed Vireo            60\n",
       "Rose breasted Grosbeak    60\n",
       "Pine Grosbeak             60\n",
       "Evening Grosbeak          60\n",
       "Name: class_name, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_df_label_vc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1cdc99d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Whip poor Will       49\n",
       "Rhinoceros Auklet    48\n",
       "Spotted Catbird      45\n",
       "Crested Auklet       44\n",
       "Least Auklet         41\n",
       "Name: class_name, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_df_label_vc.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bfb4981b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_df_label_vc.hist( bins = 50 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abf9357",
   "metadata": {},
   "source": [
    "Most classes have 350 datapoints because I *thought* I had downsampled the datasets with more than 350 datapoints down to 350 but it looks like there are some that were not affected by the transformation I performed. There are some classes with more than 350 datapoints somehow. Regardless, we will be downsampling them all to the lowest value_count (101)..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e853b53e",
   "metadata": {},
   "source": [
    "### Dataset Transformation\n",
    "(downsample, upsample, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8de0672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampling to least number of samples per class: 41\n"
     ]
    }
   ],
   "source": [
    "# Downsample to equal number of samples per class if downsample param is set\n",
    "if ( run['dataset']['downsample'] ):\n",
    "    # if downsample param is 'min', downsample all classes to the same number of\n",
    "    # samples as the class with the least samples\n",
    "    if ( run['dataset']['downsample'] == 'min' ):\n",
    "        ds_df_label_vc_min = ds_df_label_vc.min()\n",
    "        print('Downsampling to least number of samples per class: %d' % ds_df_label_vc_min)\n",
    "    else:\n",
    "        # manual override\n",
    "        if ( run['dataset']['downsample'] > 0 ):\n",
    "            print( 'Overriding samples per class to: %d' % run['dataset']['downsample'] )\n",
    "            ds_df_label_vc_min = run['dataset']['downsample']\n",
    "        else: raise Exception(\"dataset downsample invalid\")\n",
    "    \n",
    "    # downsample based on \n",
    "    ds_df_trans = ds_df.groupby( by = datasets[ run['dataset']['source'] ].col_label ).sample( n = ds_df_label_vc_min )\n",
    "    ds_df_trans[ datasets[ run['dataset']['source'] ].col_label ].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3bb10a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41    200\n",
       "Name: class_name, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verifying that our downsampling worked - all classes should have the same value_count\n",
    "ds_df_trans[ datasets[ run['dataset']['source'] ].col_label ].value_counts().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a66265",
   "metadata": {},
   "source": [
    "We have transformed the original dataset through downsampling to produce a dataset where all classes have the same number of datapoints as the class with the least amount of datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "27c1d12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New datapoint count: 8200\n"
     ]
    }
   ],
   "source": [
    "print( 'New datapoint count: %d' % len(ds_df_trans) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d63aa1b",
   "metadata": {},
   "source": [
    "### Train, Validation, Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6507235",
   "metadata": {},
   "outputs": [],
   "source": [
    "run['dataset']['split_test'] = 0.05\n",
    "run['dataset']['split_val'] = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b5d088d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate random states for reproducability\n",
    "import random\n",
    "\n",
    "# [0, 2**32 - 1]\n",
    "run['dataset']['seed_split_test'] = random.randint( 0, 2**32 - 1 )\n",
    "run['dataset']['seed_split_val'] = random.randint( 0, 2**32 - 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "722fd1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "ds_df_train, ds_df_test = train_test_split(\n",
    "    ds_df_trans,\n",
    "    test_size = run['dataset']['split_test'],\n",
    "    stratify = ds_df_trans[[ datasets[ run['dataset']['source'] ].col_label ]],\n",
    "    random_state = run['dataset']['seed_split_test'],\n",
    ")\n",
    "\n",
    "# val\n",
    "ds_df_train, ds_df_val = train_test_split(\n",
    "    ds_df_train,\n",
    "    test_size = run['dataset']['split_val'],\n",
    "    stratify = ds_df_train[[ datasets[ run['dataset']['source'] ].col_label ]],\n",
    "    random_state = run['dataset']['seed_split_val'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e04a392",
   "metadata": {},
   "source": [
    "### Input Data Pipeline Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "57fab483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(\n",
    "    filename,\n",
    "):\n",
    "    img_raw = tf.io.read_file( filename )\n",
    "    img_tensor = tf.image.decode_image(\n",
    "        img_raw,\n",
    "        dtype = tf.dtypes.float32,\n",
    "        channels = 3,\n",
    "        expand_animations = False,\n",
    "    )\n",
    "    return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e9a3cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(\n",
    "    img_tensor,\n",
    "    input_dim,\n",
    "):\n",
    "    return tf.image.resize(\n",
    "        img_tensor,\n",
    "        [ input_dim, input_dim ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2635233b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(\n",
    "    img_tensor,\n",
    "    preprocessor,\n",
    "):\n",
    "    return preprocessor( img_tensor )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aae5074d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_label_encoder( label, mapping ):\n",
    "    one_hot = label == mapping\n",
    "    label_encoded = tf.argmax( one_hot )\n",
    "    return label_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "848b3561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_label(\n",
    "    label,\n",
    "    label_encoder,\n",
    "):\n",
    "    return label_encoder( label )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d3c05ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(\n",
    "    img_tensor,\n",
    "    augmentation_func,\n",
    "):\n",
    "    return augmentation_func( img_tensor, training = True )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "21f1d384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation function selection\n",
    "augmentation_functions = [\n",
    "    tf.keras.Sequential( [\n",
    "        tf.keras.layers.RandomFlip( \"horizontal_and_vertical\" ),\n",
    "        tf.keras.layers.RandomRotation( 0.2 ),\n",
    "    ] )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9237d8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set augmentation_func to None if no augmentation is desired\n",
    "# augmentation_func = augmentation_functions[0]\n",
    "augmentation_func = None\n",
    "\n",
    "# Determines if data augmentation should be done in the IDP or in the model\n",
    "# Data augmentation will\n",
    "data_augmentation_in_ds = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b0021e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a buffersize equal to the length of the dataset\n",
    "shuffle_buffer_size = int( len( ds_df_train ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "93eaac1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate and save the shuffle random seed\n",
    "run['dataset']['seed_shuffle'] = tf.random.uniform(\n",
    "    shape = (),\n",
    "    dtype = tf.int64,\n",
    "    maxval = tf.int64.max,\n",
    ").numpy()\n",
    "# make it json serializable...\n",
    "run['dataset']['seed_shuffle'] = int( run['dataset']['seed_shuffle'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "54a0222a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determines if preprocessing should be done in the IDP or in the model\n",
    "preprocessing_in_ds = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ffc84037",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charlescoult/.conda/envs/fungi/lib/python3.10/site-packages/numpy/core/numeric.py:2468: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n"
     ]
    }
   ],
   "source": [
    "# label encoding\n",
    "# (img_tensor_resized_preprocessed, label_encoded)\n",
    "label_encoder = tf.keras.layers.StringLookup(\n",
    "    vocabulary = ds_classes,\n",
    "    # sparse = True,\n",
    "    output_mode = 'one_hot',\n",
    "    num_oov_indices = 0,\n",
    ")\n",
    "\n",
    "def make_idp(\n",
    "    filenames,\n",
    "    labels,\n",
    "    input_dim,\n",
    "    is_training = False,\n",
    "    batch_size = 32,\n",
    "    augmentation_func = None,\n",
    "):\n",
    "    ds = tf.data.Dataset.from_tensor_slices( (\n",
    "        filenames,\n",
    "        labels,\n",
    "    ) )\n",
    "\n",
    "    # if isTraining, shuffle\n",
    "    if ( is_training ):\n",
    "        ds = ds.shuffle(\n",
    "            buffer_size = shuffle_buffer_size,\n",
    "            seed = run['dataset']['seed_shuffle'],\n",
    "        )\n",
    "\n",
    "    # image loading\n",
    "    # (img_tensor, label)\n",
    "    ds = ds.map(\n",
    "        lambda filename, label: (\n",
    "            load_image(filename),\n",
    "            label,\n",
    "        ),\n",
    "        num_parallel_calls = AUTOTUNE,\n",
    "    )\n",
    "\n",
    "    # if isTraining and augmentation_func exists, use data augmentation\n",
    "    if ( is_training and data_augmentation_in_ds and augmentation_func ):\n",
    "        logging.info(\"Adding data augmentation.\")\n",
    "        ds = ds.map(\n",
    "            lambda img_tensor, label: (\n",
    "                data_augmentation(img_tensor, augmentation_func),\n",
    "                label,\n",
    "            ),\n",
    "            num_parallel_calls = AUTOTUNE,\n",
    "        )\n",
    "    \n",
    "    # image resizing\n",
    "    # (img_tensor_resized, label)\n",
    "    ds = ds.map(\n",
    "        lambda img_tensor, label: (\n",
    "            resize( img_tensor, input_dim ),\n",
    "            label,\n",
    "        ),\n",
    "        num_parallel_calls = AUTOTUNE,\n",
    "    )\n",
    "    \n",
    "    # image preprocessing\n",
    "    # (img_tensor_resized_preprocessed, label)\n",
    "    if ( preprocessing_in_ds ):\n",
    "        ds = ds.map(\n",
    "            lambda img_tensor_resized, label: (\n",
    "                preprocessing( img_tensor_resized, base_models[ run['model']['base'] ].preprocessor ),\n",
    "                label,\n",
    "            ),\n",
    "            num_parallel_calls = AUTOTUNE,\n",
    "        )\n",
    "\n",
    "\n",
    "    ds = ds.map(\n",
    "        lambda img_tensor_resized_preprocessed, label: (\n",
    "            img_tensor_resized_preprocessed,\n",
    "            encode_label( label, label_encoder ),\n",
    "            # encode_label( label, lambda x: my_label_encoder( x, ds_classes ) ),\n",
    "        ),\n",
    "        num_parallel_calls = AUTOTUNE,\n",
    "    )\n",
    "\n",
    "    # Batch\n",
    "    ds = ds.batch( batch_size )\n",
    "    \n",
    "    # Prefetch\n",
    "    ds = ds.prefetch( buffer_size = AUTOTUNE )\n",
    "    \n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dbefbe53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/charlescoult/.conda/envs/fungi/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/charlescoult/.conda/envs/fungi/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "# IDP creation\n",
    "ds_idp_train = make_idp(\n",
    "    ds_df_train[ datasets[ run['dataset']['source'] ].col_filename ].values,\n",
    "    ds_df_train[ datasets[ run['dataset']['source'] ].col_label ].values,\n",
    "    input_dim = base_models[ run['model']['base'] ].input_dim,\n",
    "    is_training = True,\n",
    "    batch_size = run['batch_size'],\n",
    "    augmentation_func = augmentation_func if ( augmentation_func ) else None,\n",
    ")\n",
    "\n",
    "ds_idp_val = make_idp(\n",
    "    ds_df_val[ datasets[ run['dataset']['source'] ].col_filename ].values,\n",
    "    ds_df_val[ datasets[ run['dataset']['source'] ].col_label ].values,\n",
    "    input_dim = base_models[ run['model']['base'] ].input_dim,\n",
    "    is_training = False,\n",
    "    batch_size = run['batch_size'],\n",
    "    # turned off by is_training = False anyway...\n",
    "    augmentation_func = None,\n",
    ")\n",
    "\n",
    "ds_idp_test = make_idp(\n",
    "    ds_df_test[ datasets[ run['dataset']['source'] ].col_filename ].values,\n",
    "    ds_df_test[ datasets[ run['dataset']['source'] ].col_label ].values,\n",
    "    input_dim = base_models[ run['model']['base'] ].input_dim,\n",
    "    is_training = False,\n",
    "    batch_size = run['batch_size'],\n",
    "    # turned off by is_training = False anyway...\n",
    "    augmentation_func = None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2815244b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]], shape=(64, 200), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for el in ds_idp_train.take(1):\n",
    "    print(el[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de845ab",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1aa7788",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9a0c6376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return a name that accurately describes the model building function or\n",
    "# the tfhub model (by url) that was passed\n",
    "def get_model_name( model_handle ):\n",
    "\n",
    "    if callable(model_handle):\n",
    "        return f'keras.applications/{model_handle.__name__}'\n",
    "    else:\n",
    "        split = model_handle.split('/')\n",
    "        return f'tfhub/{split[-5]}.{split[-4]}.{split[-3]}'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3acf9abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize full model\n",
    "full_model = tf.keras.Sequential( name = \"full_model\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ad741a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if preprocessing_in_ds, then input is assumed to be preprocessed correctly from input dataset pipeline (idp)\n",
    "# else, add preprocessing layer to model\n",
    "if ( not preprocessing_in_ds ):\n",
    "    raise Exception('not yet implemented')\n",
    "    full_model.add(\n",
    "        \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a91f6bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate base_model layer\n",
    "def gen_base_model_layer(\n",
    "    name,\n",
    "    source,\n",
    "    input_dim,\n",
    "    trainable = False,\n",
    "):\n",
    "    # If model_handle is a model building function, use that function\n",
    "    if callable( source ):\n",
    "        base_model = source(\n",
    "            include_top = False,\n",
    "            input_shape = ( input_dim, input_dim ) + (3,),\n",
    "            weights = 'imagenet',\n",
    "            # pooling = 'avg',\n",
    "        )\n",
    "\n",
    "    # otherwise build a layer from the tfhub url that was passed as a string\n",
    "    else:\n",
    "        base_model = hub.KerasLayer(\n",
    "            source,\n",
    "            input_shape = ( input_dim, input_dim ) + (3,),\n",
    "            name = name,\n",
    "        )\n",
    "    \n",
    "    base_model.trainable = trainable\n",
    "\n",
    "    return base_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fa51aae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n",
      "INFO:absl:Using /tmp/tfhub_modules to cache modules.\n"
     ]
    }
   ],
   "source": [
    "# Add base model to full_model\n",
    "full_model.add( gen_base_model_layer(\n",
    "    name = get_model_name( base_models[ run['model']['base'] ].source ),\n",
    "    source = base_models[ run['model']['base'] ].source,\n",
    "    input_dim = base_models[ run['model']['base'] ].input_dim,\n",
    "    trainable = True,\n",
    ") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "48d708e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate classifier\n",
    "def gen_classifier_model_layer(\n",
    "    num_classes,\n",
    "    dropout,\n",
    "    add_softmax = False,\n",
    "):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(\n",
    "        layers.Dense(\n",
    "            num_classes,\n",
    "            # activation = 'softmax',\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.add(\n",
    "        layers.Dropout(dropout),\n",
    "    )\n",
    "\n",
    "    if ( add_softmax ):\n",
    "        model.add(\n",
    "            layers.Activation(\"softmax\", dtype=\"float32\"),\n",
    "        )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6aa4dddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "run['model']['classifier']['output_logits'] = True\n",
    "# Add classifier model to full_model\n",
    "# TODO allow selection between different classification models\n",
    "full_model.add( gen_classifier_model_layer(\n",
    "    num_classes = len( ds_classes ),\n",
    "    dropout = run['model']['classifier']['dropout'],\n",
    "    add_softmax = not run['model']['classifier']['output_logits'],\n",
    ") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65bf126",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5b6575",
   "metadata": {},
   "source": [
    "* Note regarding `thawed_base_model_layers` and full model architecture ([reference](https://stackoverflow.com/questions/64227483/what-is-the-right-way-to-gradually-unfreeze-layers-in-neural-network-while-learn))\n",
    "![image](https://i.stack.imgur.com/JLJqv.png)\n",
    "* [Another great reference](https://towardsdatascience.com/transfer-learning-from-pre-trained-models-f2393f124751)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253c44ee",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0881edf",
   "metadata": {},
   "source": [
    "# Training Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ed107505",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training\n",
    "max_epochs = 20\n",
    "\n",
    "### Optimizer\n",
    "learning_rate = 0.0001\n",
    "\n",
    "### Loss\n",
    "label_smoothing = 0.1\n",
    "\n",
    "# TODO: allow loading of model weights from previous run\n",
    "load_weights = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b6bce53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "# Sparse vs non-sparse CCE https://www.kaggle.com/general/197993\n",
    "full_model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam( learning_rate = learning_rate ),\n",
    "    # loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    #     from_logits = True,\n",
    "    # ),\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy(\n",
    "        from_logits = run['model']['classifier']['output_logits'],\n",
    "        # label_smoothing = label_smoothing,\n",
    "    ),\n",
    "    metrics = [\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.AUC(),\n",
    "        # tf.keras.metrics.SparseCategoricalCrossentropy(),\n",
    "        # tf.keras.metrics.SparseTopKCategoricalAccuracy(\n",
    "        #     k = 3,\n",
    "        #     name = \"Top3\",\n",
    "        # ),\n",
    "        # tf.keras.metrics.SparseTopKCategoricalAccuracy(\n",
    "        #     k = 10,\n",
    "        #     name=\"Top10\",\n",
    "        # ),\n",
    "        # tf.keras.metrics.CategoricalCrossentropy(),            \n",
    "        # tf.keras.metrics.TopKCategoricalAccuracy( k=3, name=\"Top3\" ),\n",
    "        # tf.keras.metrics.TopKCategoricalAccuracy( k=10, name=\"Top10\" ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9df29b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard logs\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir = run['path'],\n",
    "    histogram_freq = 1,\n",
    ")\n",
    "\n",
    "# Early stopping\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    # monitor='val_sparse_categorical_accuracy',\n",
    "    monitor = 'val_loss',\n",
    "    patience = 5,\n",
    "    min_delta = 0.01,\n",
    ")\n",
    "\n",
    "# Model Checkpoints for saving best model weights\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    os.path.join( runs['path'], 'best_model' ),\n",
    "    save_best_only = True,\n",
    "    monitor = 'val_loss',\n",
    "    # mode = 'min', # should be chosen correctly based on monitor value\n",
    ")\n",
    "\n",
    "class TimeCallback( tf.keras.callbacks.Callback ):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        metric_name = 'epoch_duration',\n",
    "    ):\n",
    "        self.__epoch_start = None\n",
    "        self.__metric_name = metric_name\n",
    "    \n",
    "    def on_epoch_begin(\n",
    "        self,\n",
    "        epoch,\n",
    "        logs = None,\n",
    "    ):\n",
    "        self.__epoch_start = datetime.datetime.utcnow()\n",
    "        \n",
    "    def on_epoch_end(\n",
    "    ):\n",
    "        logs[ self.__metric_name ] = datetime.datetime.utcnow() - self.__epoch_start\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    tensorboard_callback,\n",
    "    early_stopping_callback,\n",
    "    model_checkpoint_callback,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "16234c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"id\": \"2023_03_19-13_25_06\",\n",
      "   \"notebook_ver\": \"0.0.1\",\n",
      "   \"path\": \"/media/data/runs/2023_03_19-13_25_06\",\n",
      "   \"batch_size\": 64,\n",
      "   \"model\": {\n",
      "      \"classifier\": {\n",
      "         \"dropout\": 0.33,\n",
      "         \"output_logits\": true\n",
      "      },\n",
      "      \"base\": \"Inception_v3_iNaturalist\"\n",
      "   },\n",
      "   \"dataset\": {\n",
      "      \"downsample\": \"min\",\n",
      "      \"source\": \"cub\",\n",
      "      \"split_test\": 0.05,\n",
      "      \"split_val\": 0.1,\n",
      "      \"seed_split_test\": 1330113942,\n",
      "      \"seed_split_val\": 3266425361,\n",
      "      \"seed_shuffle\": 6624289850950107849\n",
      "   },\n",
      "   \"label_mapping_path\": \"/media/data/runs/2023_03_19-13_25_06/label_mapping.json\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print_run_metadata( run )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "59b1eab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_37324/3436063570.py:32: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->Index(['notebook_ver', 'path', 'label_mapping_path',\n",
      "       'model.classifier.output_logits', 'model.base', 'dataset.downsample',\n",
      "       'dataset.source'],\n",
      "      dtype='object')]\n",
      "\n",
      "  runs_df.to_hdf( runs_hdf_path, runs_hdf_key )\n"
     ]
    }
   ],
   "source": [
    "save_run_metadata( run )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "510fdab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "110/110 [==============================] - ETA: 0s - loss: 3.7237 - accuracy: 0.3964"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) tfhub/google.inaturalist.inception_v3_input with unsupported characters which will be renamed to tfhub_google_inaturalist_inception_v3_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 65s 389ms/step - loss: 3.7237 - accuracy: 0.3964 - val_loss: 5.6302 - val_accuracy: 0.0051\n",
      "Epoch 2/20\n",
      "110/110 [==============================] - 30s 277ms/step - loss: 2.2631 - accuracy: 0.6048 - val_loss: 5.6334 - val_accuracy: 0.0051\n",
      "Epoch 3/20\n",
      "110/110 [==============================] - 31s 278ms/step - loss: 1.9801 - accuracy: 0.6471 - val_loss: 5.7323 - val_accuracy: 0.0064\n",
      "Epoch 4/20\n",
      "110/110 [==============================] - ETA: 0s - loss: 1.8415 - accuracy: 0.6628"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) tfhub/google.inaturalist.inception_v3_input with unsupported characters which will be renamed to tfhub_google_inaturalist_inception_v3_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 35s 315ms/step - loss: 1.8415 - accuracy: 0.6628 - val_loss: 5.3666 - val_accuracy: 0.0488\n",
      "Epoch 5/20\n",
      "110/110 [==============================] - 30s 271ms/step - loss: 1.8300 - accuracy: 0.6571 - val_loss: 5.6787 - val_accuracy: 0.0116\n",
      "Epoch 6/20\n",
      "110/110 [==============================] - 30s 270ms/step - loss: 1.7227 - accuracy: 0.6759 - val_loss: 5.6163 - val_accuracy: 0.0218\n",
      "Epoch 7/20\n",
      "110/110 [==============================] - ETA: 0s - loss: 1.7217 - accuracy: 0.6718"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) tfhub/google.inaturalist.inception_v3_input with unsupported characters which will be renamed to tfhub_google_inaturalist_inception_v3_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 35s 316ms/step - loss: 1.7217 - accuracy: 0.6718 - val_loss: 3.3074 - val_accuracy: 0.3748\n",
      "Epoch 8/20\n",
      "110/110 [==============================] - 30s 274ms/step - loss: 1.6773 - accuracy: 0.6789 - val_loss: 5.7177 - val_accuracy: 0.0116\n",
      "Epoch 9/20\n",
      "110/110 [==============================] - 30s 274ms/step - loss: 1.7151 - accuracy: 0.6675 - val_loss: 4.5390 - val_accuracy: 0.1746\n",
      "Epoch 10/20\n",
      "110/110 [==============================] - ETA: 0s - loss: 1.6611 - accuracy: 0.6785"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) tfhub/google.inaturalist.inception_v3_input with unsupported characters which will be renamed to tfhub_google_inaturalist_inception_v3_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 35s 315ms/step - loss: 1.6611 - accuracy: 0.6785 - val_loss: 3.1633 - val_accuracy: 0.4005\n",
      "Epoch 11/20\n",
      "110/110 [==============================] - ETA: 0s - loss: 1.6649 - accuracy: 0.6774"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) tfhub/google.inaturalist.inception_v3_input with unsupported characters which will be renamed to tfhub_google_inaturalist_inception_v3_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 35s 314ms/step - loss: 1.6649 - accuracy: 0.6774 - val_loss: 1.3032 - val_accuracy: 0.7959\n",
      "Epoch 12/20\n",
      "110/110 [==============================] - ETA: 0s - loss: 1.7088 - accuracy: 0.6672"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) tfhub/google.inaturalist.inception_v3_input with unsupported characters which will be renamed to tfhub_google_inaturalist_inception_v3_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 35s 315ms/step - loss: 1.7088 - accuracy: 0.6672 - val_loss: 0.9344 - val_accuracy: 0.8460\n",
      "Epoch 13/20\n",
      "110/110 [==============================] - ETA: 0s - loss: 1.6217 - accuracy: 0.6862"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) tfhub/google.inaturalist.inception_v3_input with unsupported characters which will be renamed to tfhub_google_inaturalist_inception_v3_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 34s 310ms/step - loss: 1.6217 - accuracy: 0.6862 - val_loss: 0.7692 - val_accuracy: 0.8832\n",
      "Epoch 14/20\n",
      "110/110 [==============================] - 30s 271ms/step - loss: 1.6546 - accuracy: 0.6785 - val_loss: 2.6478 - val_accuracy: 0.4994\n",
      "Epoch 15/20\n",
      "110/110 [==============================] - 30s 274ms/step - loss: 1.7119 - accuracy: 0.6650 - val_loss: 0.9498 - val_accuracy: 0.8472\n",
      "Epoch 16/20\n",
      "110/110 [==============================] - 30s 273ms/step - loss: 1.6663 - accuracy: 0.6742 - val_loss: 0.9544 - val_accuracy: 0.8485\n",
      "Epoch 17/20\n",
      "110/110 [==============================] - 30s 274ms/step - loss: 1.6319 - accuracy: 0.6829 - val_loss: 0.7949 - val_accuracy: 0.8819\n",
      "Epoch 18/20\n",
      "110/110 [==============================] - 30s 270ms/step - loss: 1.6545 - accuracy: 0.6761 - val_loss: 0.8233 - val_accuracy: 0.8768\n",
      "Completed.\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "timer['train_start'] = time.perf_counter()\n",
    "\n",
    "try:\n",
    "    history = full_model.fit(\n",
    "        ds_idp_train,\n",
    "        validation_data = ds_idp_val,\n",
    "        epochs = max_epochs,\n",
    "        callbacks = callbacks,\n",
    "        # validation_freq=2,\n",
    "    )\n",
    "except KeyboardInterrupt:\n",
    "    print('\\n\\nInterrupted...')\n",
    "    # run['interrupted'] = True\n",
    "else:\n",
    "    print('Completed.')\n",
    "    # run['interrupted'] = False\n",
    "    \n",
    "timer['train_end'] = time.perf_counter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4b85bd8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603.8708942999983\n"
     ]
    }
   ],
   "source": [
    "run['time'] = timer['train_end'] - timer['train_start']\n",
    "print(run['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9974f8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterdict( d ):\n",
    "    for k,v in d.items():\n",
    "        if isinstance(v, dict):\n",
    "            iterdict(v)\n",
    "        else:\n",
    "            print(k, type(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b46688fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id <class 'str'>\n",
      "notebook_ver <class 'str'>\n",
      "path <class 'str'>\n",
      "batch_size <class 'int'>\n",
      "dropout <class 'float'>\n",
      "output_logits <class 'bool'>\n",
      "base <class 'str'>\n",
      "downsample <class 'str'>\n",
      "source <class 'str'>\n",
      "split_test <class 'float'>\n",
      "split_val <class 'float'>\n",
      "seed_split_test <class 'int'>\n",
      "seed_split_val <class 'int'>\n",
      "seed_shuffle <class 'int'>\n",
      "label_mapping_path <class 'str'>\n",
      "time <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "iterdict( run )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "91731c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_37324/3436063570.py:32: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->Index(['notebook_ver', 'path', 'label_mapping_path',\n",
      "       'model.classifier.output_logits', 'model.base', 'dataset.downsample',\n",
      "       'dataset.source'],\n",
      "      dtype='object')]\n",
      "\n",
      "  runs_df.to_hdf( runs_hdf_path, runs_hdf_key )\n"
     ]
    }
   ],
   "source": [
    "save_run_metadata( run )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-fungi]",
   "language": "python",
   "name": "conda-env-.conda-fungi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
