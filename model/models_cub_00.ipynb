{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "518a0c58",
   "metadata": {},
   "source": [
    "# Models Exploration using CUB dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b411778a",
   "metadata": {},
   "source": [
    "## References\n",
    "* [Transfer Learning with Hub](https://www.tensorflow.org/tutorials/images/transfer_learning_with_hub)\n",
    "* [`tf.keras.utils.image_dataset_from_directory`](https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory)\n",
    "* [Limiting GPU Memory Growth](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a285c8a1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2c0f4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "from keras.utils.layer_utils import count_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eeaabc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_memory_growth(limit=True):\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            # Currently, memory growth needs to be the same across GPUs\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, limit)\n",
    "            logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "        except RuntimeError as e:\n",
    "            # Memory growth must be set before GPUs have been initialized\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5bbc7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "limit_memory_growth()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3e8d4f",
   "metadata": {},
   "source": [
    "## Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47fe9ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(\n",
    "    image_batch,\n",
    "    predicted_class_names,\n",
    "):\n",
    "    plt.figure(figsize=(10,9))\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "    for n in range(30):\n",
    "        plt.subplot(6,5,n+1)\n",
    "        plt.imshow(image_batch[n])\n",
    "        plt.title(predicted_class_names[n])\n",
    "        plt.axis('off')\n",
    "    _ = plt.suptitle(\"Predictions\")\n",
    "\n",
    "def plot_images(\n",
    "    ds,\n",
    "    class_names,\n",
    "):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for images, labels in ds.take(1):\n",
    "        for i in range(9):\n",
    "            ax = plt.subplot(3, 3, i + 1)\n",
    "            plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "            plt.title(class_names[labels[i]])\n",
    "            plt.axis(\"off\")\n",
    "    \n",
    "def get_timestamp():\n",
    "    return datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7b7729",
   "metadata": {},
   "source": [
    "## Enumerate Datasets to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "164195db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "flowers_dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "flowers_data_dir = tf.keras.utils.get_file('flower_photos', origin=flowers_dataset_url, untar=True)\n",
    "flowers_data_dir = pathlib.Path(flowers_data_dir)\n",
    "\n",
    "datasets = [\n",
    "    '/mnt/cub/CUB_200_2011/images',\n",
    "    flowers_data_dir,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c9c943",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd46f988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(\n",
    "    data_dir = '/mnt/cub/CUB_200_2011/images',\n",
    "    batch_size = 64,\n",
    "    image_size = (299,299),\n",
    "    preprocess_input = None,\n",
    "    # normalization = True,\n",
    "):\n",
    "   \n",
    "    '''\n",
    "    train_ds, val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        data_dir,\n",
    "        batch_size = batch_size,\n",
    "        validation_split = 0.2,\n",
    "        image_size = image_size,\n",
    "        subset = \"both\",\n",
    "        shuffle = True, # default but here for clarity\n",
    "        seed=42,\n",
    "    )\n",
    "    '''\n",
    "    datagen = ImageDataGenerator(\n",
    "        preprocessing_function = preprocess_input,\n",
    "        validation_split=0.2,\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.15,\n",
    "        zoom_range=0.1,\n",
    "        channel_shift_range=10.,\n",
    "        horizontal_flip=True,\n",
    "    )\n",
    "    \n",
    "    train_ds = datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=(299,299),\n",
    "        batch_size=batch_size,\n",
    "        subset='training',\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    val_ds = datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=(299,299),\n",
    "        batch_size=batch_size,\n",
    "        subset='validation',\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "    '''\n",
    "\n",
    "    # Use model specific preprocessing function\n",
    "    if preprocess_input:\n",
    "        train_ds.map(lambda x, y: (preprocess_input(x), y))\n",
    "        val_ds.map(lambda x, y: (preprocess_input(x), y))\n",
    "    else:\n",
    "        # normalization_layer = layers.Rescaling(\n",
    "        #     1./255,\n",
    "        #     name=\"normalization_layer\",\n",
    "        # )\n",
    "        # train_ds.map(lambda x, y: (normalization_layer(x)-0.5, y))\n",
    "        # val_ds.map(lambda x, y: (normalization_layer(x)-0.5, y))\n",
    "        pass\n",
    "    '''\n",
    "    \n",
    "    # Retrieve number of classes\n",
    "    # (can't do this after converting to PrefetchDataset)\n",
    "    #num_classes = len(train_ds.class_names)\n",
    "    num_classes = 200\n",
    "    \n",
    "    # print(num_classes) # 200\n",
    "    \n",
    "    # Prefetch images\n",
    "    # train_ds = train_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    # val_ds = val_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    \n",
    "    \n",
    "    return (train_ds, val_ds, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cf56f3",
   "metadata": {},
   "source": [
    "## Enumerate Models to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee979c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models_metadata = [\n",
    "    # ('https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4', 224),\n",
    "    # ('https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/4', 299),\n",
    "    # ('https://tfhub.dev/google/inaturalist/inception_v3/feature_vector/5', 299),\n",
    "    (tf.keras.applications.Xception, 299, tf.keras.applications.xception.preprocess_input),\n",
    "    # (tf.keras.applications.resnet.ResNet101, 224),\n",
    "    # (tf.keras.applications.ResNet50, 224),\n",
    "    # (tf.keras.applications.InceptionResNetV2, 299),\n",
    "    # (tf.keras.applications.efficientnet_v2.EfficientNetV2B0, 224)\n",
    "]\n",
    "\n",
    "def get_model_name( model_handle ):\n",
    "    \n",
    "    if callable(model_handle):\n",
    "        return f'keras.applications.{model_handle.__name__}'\n",
    "    else:\n",
    "        split = model_handle.split('/')\n",
    "        return f'{split[-5]}.{split[-4]}.{split[-3]}'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1aa7788",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a06cf38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model weight counts\n",
    "def print_weight_counts(model):\n",
    "    print(f'Full Model - Non-trainable weights: {count_params(model.non_trainable_weights)}')\n",
    "    print(f'Full Model - Trainable weights: {count_params(model.trainable_weights)}')\n",
    "\n",
    "def build_base_model_layer(\n",
    "    model_handle,\n",
    "    name=\"base_model_layer\",\n",
    "):\n",
    "    if callable(model_handle):\n",
    "        base_model_layer = model_handle(\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            pooling = 'avg',\n",
    "        )\n",
    "        base_model_layer.trainable = False\n",
    "    else:\n",
    "        base_model_layer = hub.KerasLayer(\n",
    "            model_handle,\n",
    "            name=name,\n",
    "            trainable = False, # default but here for clarity\n",
    "        )\n",
    "        \n",
    "    # Print Base model weights\n",
    "    print(\"Base Model:\")\n",
    "    print_weight_counts(base_model_layer)\n",
    "    print()\n",
    "    \n",
    "    return base_model_layer\n",
    "\n",
    "def build_model(\n",
    "    base_model_metadata,\n",
    "    dropout,\n",
    "    num_classes = 200,\n",
    "):\n",
    "    model_handle, input_dimension, preprocess_input = base_model_metadata\n",
    "\n",
    "    model = Sequential([\n",
    "        # layers.Lambda(preprocess_input),\n",
    "        build_base_model_layer(\n",
    "            model_handle,\n",
    "        ),\n",
    "        layers.Dense(\n",
    "            num_classes,\n",
    "            # activation = 'softmax',\n",
    "        ),\n",
    "        layers.Dropout(dropout),\n",
    "        layers.Activation(\"softmax\", dtype=\"float32\"),\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    # Print weight counts\n",
    "    print(\"Full Model:\")\n",
    "    print_weight_counts(model)\n",
    "    print()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4286d70",
   "metadata": {},
   "source": [
    "## Build and run all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03b3f0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9465 images belonging to 200 classes.\n",
      "Found 2323 images belonging to 200 classes.\n",
      "Base Model:\n",
      "Full Model - Non-trainable weights: 20861480\n",
      "Full Model - Trainable weights: 0\n",
      "\n",
      "Full Model:\n",
      "Full Model - Non-trainable weights: 20861480\n",
      "Full Model - Trainable weights: 409800\n",
      "\n",
      "\n",
      "keras.applications.Xception\n",
      "Epoch 1/15\n",
      "148/148 [==============================] - 149s 947ms/step - loss: 4.6720 - accuracy: 0.1351 - val_loss: 3.7836 - val_accuracy: 0.3517\n",
      "Epoch 2/15\n",
      "148/148 [==============================] - 127s 855ms/step - loss: 3.7263 - accuracy: 0.3203 - val_loss: 3.0891 - val_accuracy: 0.4959\n",
      "Epoch 3/15\n",
      "148/148 [==============================] - 132s 896ms/step - loss: 3.3670 - accuracy: 0.3869 - val_loss: 2.7299 - val_accuracy: 0.5618\n",
      "Epoch 4/15\n",
      "148/148 [==============================] - 133s 897ms/step - loss: 3.1933 - accuracy: 0.4161 - val_loss: 2.5111 - val_accuracy: 0.5846\n",
      "Epoch 5/15\n",
      "148/148 [==============================] - 130s 878ms/step - loss: 3.0447 - accuracy: 0.4428 - val_loss: 2.3306 - val_accuracy: 0.6117\n",
      "Epoch 6/15\n",
      "148/148 [==============================] - 119s 801ms/step - loss: 2.9519 - accuracy: 0.4571 - val_loss: 2.2287 - val_accuracy: 0.6117\n",
      "Epoch 7/15\n",
      "148/148 [==============================] - 117s 792ms/step - loss: 2.9013 - accuracy: 0.4631 - val_loss: 2.1199 - val_accuracy: 0.6289\n",
      "Epoch 8/15\n",
      "148/148 [==============================] - 118s 800ms/step - loss: 2.7775 - accuracy: 0.4861 - val_loss: 2.0574 - val_accuracy: 0.6311\n",
      "Epoch 9/15\n",
      "148/148 [==============================] - 118s 795ms/step - loss: 2.7974 - accuracy: 0.4768 - val_loss: 1.9915 - val_accuracy: 0.6483\n",
      "Epoch 10/15\n",
      "148/148 [==============================] - 118s 799ms/step - loss: 2.7603 - accuracy: 0.4849 - val_loss: 1.9418 - val_accuracy: 0.6427\n",
      "Epoch 11/15\n",
      "148/148 [==============================] - 118s 797ms/step - loss: 2.6865 - accuracy: 0.4945 - val_loss: 1.8899 - val_accuracy: 0.6513\n",
      "Epoch 12/15\n",
      "148/148 [==============================] - 118s 798ms/step - loss: 2.6846 - accuracy: 0.4919 - val_loss: 1.8575 - val_accuracy: 0.6492\n",
      "Epoch 13/15\n",
      "148/148 [==============================] - 118s 801ms/step - loss: 2.6535 - accuracy: 0.5002 - val_loss: 1.8176 - val_accuracy: 0.6552\n",
      "Epoch 14/15\n",
      "148/148 [==============================] - 118s 800ms/step - loss: 2.6211 - accuracy: 0.5047 - val_loss: 1.8033 - val_accuracy: 0.6526\n",
      "Epoch 15/15\n",
      "148/148 [==============================] - ETA: 0s - loss: 2.5752 - accuracy: 0.5117"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "max_epochs = 15\n",
    "dropout = 0.4\n",
    "learning_rate = 0.0005\n",
    "\n",
    "# Directory for logs\n",
    "base_log_dir = \"models_cub_logs\"\n",
    "\n",
    "# for each base model\n",
    "for base_model_metadata in base_models_metadata:\n",
    "    \n",
    "    model_handle, input_dimension, preprocess_input = base_model_metadata\n",
    "\n",
    "    image_size = (input_dimension, input_dimension)\n",
    "    \n",
    "    # Build dataset/pipeline\n",
    "    train_ds, val_ds, num_classes = build_dataset(\n",
    "        datasets[0],\n",
    "        batch_size = batch_size,\n",
    "        image_size = image_size,\n",
    "        preprocess_input = preprocess_input,\n",
    "    )\n",
    "    \n",
    "    # plot_images(train_ds, )\n",
    "\n",
    "    # Build model\n",
    "    model = build_model(\n",
    "        base_model_metadata,\n",
    "        dropout,\n",
    "        num_classes,\n",
    "    )\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        # loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(\n",
    "            # from_logits=True,\n",
    "        ),\n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            # tf.keras.metrics.SparseCategoricalAccuracy(),\n",
    "            # tf.keras.metrics.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            # tf.keras.metrics.SparseTopKCategoricalAccuracy(k=3, name=\"Top3\"),\n",
    "            # tf.keras.metrics.SparseTopKCategoricalAccuracy(k=10, name=\"Top10\"),\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    # Logging\n",
    "    model_id = get_model_name(model_handle)\n",
    "    log_dir = os.path.join( base_log_dir, model_id )\n",
    "    \n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=log_dir,\n",
    "        histogram_freq=1,\n",
    "    )\n",
    "    \n",
    "    # Early stopping\n",
    "    early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "        # monitor='val_sparse_categorical_accuracy',\n",
    "        monitor='accuracy',\n",
    "        patience=5,\n",
    "        min_delta=0.001,\n",
    "    ),\n",
    "    \n",
    "    print()\n",
    "    print(model_id)\n",
    "    \n",
    "    # Train\n",
    "    model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=max_epochs,\n",
    "        callbacks=[\n",
    "            tensorboard_callback,\n",
    "            early_stopping_callback,\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Save model\n",
    "    # model.save(os.path.join(log_dir, 'final_model' ))    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f61dc90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f37b01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42dfc3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65505c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-fungi] *",
   "language": "python",
   "name": "conda-env-.conda-fungi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
