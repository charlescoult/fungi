{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24ff26c3",
   "metadata": {},
   "source": [
    "# Dataset Implementation Testing\n",
    "## Objective\n",
    "To test out how to most efficiently implement our input data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22fdcd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from util import timeit\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "def load_image(\n",
    "    filename,\n",
    "    label,\n",
    "):\n",
    "    img_raw = tf.io.read_file( filename )\n",
    "    img_tensor = tf.image.decode_image(\n",
    "        img_raw,\n",
    "        channels = 3,\n",
    "        # Important to include the following\n",
    "        # https://stackoverflow.com/questions/44942729/tensorflowvalueerror-images-contains-no-shape\n",
    "        expand_animations = False,\n",
    "    )\n",
    "    return ( img_tensor, label )\n",
    "\n",
    "def preprocessing_default(\n",
    "    img_tensor,\n",
    "    label,\n",
    "):\n",
    "    img_tensor_preprocessed = tf.image.resize( img_tensor, [ 299, 299 ] )\n",
    "    img_tensor_preprocessed = img_tensor_preprocessed/255.0\n",
    "    return ( img_tensor_preprocessed, label )\n",
    "\n",
    "def load_image_dataset_from_hdf(\n",
    "    hdf_path,\n",
    "    hdf_key,\n",
    "    label_col,\n",
    "    test_size = 0.05,\n",
    "    val_size = 0.1,\n",
    "    preprocessing = preprocessing_default,\n",
    "):\n",
    "\n",
    "    df = pd.read_hdf( hdf_path, hdf_key )\n",
    "\n",
    "    # properties of the base_model\n",
    "    input_dim = 299\n",
    "    scale_coef = 1./255\n",
    "\n",
    "    # model hyperparameter\n",
    "    batch_size = 64\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "            df[ 'filename' ].values,\n",
    "            df[ label_col ].values,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    ds = ds.map(\n",
    "        load_image,\n",
    "        num_parallel_calls=AUTOTUNE,\n",
    "    )\n",
    "\n",
    "    ds = ds.map(\n",
    "        preprocessing,\n",
    "        # num_parallel_calls=AUTOTUNE,\n",
    "    )\n",
    "\n",
    "    ds = ds.batch( batch_size )\n",
    "\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2528b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/media/data/gbif'\n",
    "hdf_filename = 'clean_data.h5'\n",
    "hdf_path = os.path.join( data_dir, hdf_filename )\n",
    "hdf_key = 'media_merged_filtered-by-species_350pt'\n",
    "\n",
    "label_col = 'acceptedScientificName'\n",
    "num_batch = 100\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96d3bfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_image_dataset_from_hdf(\n",
    "    hdf_path,\n",
    "    hdf_key,\n",
    "    label_col,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c329a015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........\n",
      "100 batches: 24.269120454788208 s\n",
      "263.70960 Images/s\n",
      "Total time: 24.623489141464233s\n"
     ]
    }
   ],
   "source": [
    "timeit(\n",
    "    ds,\n",
    "    batch_size,\n",
    "    num_batch,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "933f804a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........\n",
      "100 batches: 24.22631311416626 s\n",
      "264.17557 Images/s\n",
      "Total time: 24.470304250717163s\n"
     ]
    }
   ],
   "source": [
    "dsp = ds.prefetch( buffer_size = AUTOTUNE )\n",
    "\n",
    "timeit(\n",
    "    dsp,\n",
    "    batch_size,\n",
    "    num_batch,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31419c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........\n",
      "100 batches: 28.69098401069641 s\n",
      "223.06659 Images/s\n",
      "Total time: 28.96743893623352s\n"
     ]
    }
   ],
   "source": [
    "dsc = ds.cache( filename = './cache.tf-data' )\n",
    "\n",
    "timeit(\n",
    "    dsc,\n",
    "    batch_size,\n",
    "    num_batch,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f93c0665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........\n",
      "100 batches: 25.319931030273438 s\n",
      "252.76530 Images/s\n",
      "Total time: 25.62583041191101s\n"
     ]
    }
   ],
   "source": [
    "dspc = dsp.cache( filename = './cache.tf-data' )\n",
    "\n",
    "timeit(\n",
    "    dspc,\n",
    "    batch_size,\n",
    "    num_batch,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "725dce0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........\n",
      "100 batches: 36.639801025390625 s\n",
      "174.67344 Images/s\n",
      "Total time: 36.9444694519043s\n"
     ]
    }
   ],
   "source": [
    "dscp = dsc.prefetch( buffer_size = AUTOTUNE )\n",
    "\n",
    "timeit(\n",
    "    dscp,\n",
    "    batch_size,\n",
    "    num_batch,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-fungi]",
   "language": "python",
   "name": "conda-env-.conda-fungi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
